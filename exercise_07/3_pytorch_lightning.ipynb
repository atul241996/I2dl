{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning Introduction\n",
    "\n",
    "Welcome to the introduction to [`PyTorchLightning`](https://www.pytorchlightning.ai/). PyTorch Lightning is a wrapper for PyTorch that is focused towards building neural networks model quickly by removing the boilerplate code. It also extends the functionality of PyTorch, for example, with model Callbacks and automatic porting to GPU to accelerate computations.\n",
    "\n",
    "In its essence, pytorch lightning provides a controlled setup where you are forced to in its specific partly automated library setup, but are able to customize/de-automatate each process if you so desire. You can both rely on a variety of already implemented functionalities and the fact that your code is by definition structured clearly, but at the cost of having to delve into their code structure and figuring out which functions to use.\n",
    "\n",
    "Our suggestion is to try it out. If you like it, cool, otherwise you can just stick to pytorch and build up your own library of functions you will use throughout your Deep Learning journey.\n",
    "\n",
    "Let's get started by installing PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Mount folder in Colab\n",
    "\n",
    "Uncomment thefollowing cell to mount your gdrive if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_07'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "print(sorted(os.listdir()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install correct libraries in google colab\n",
    "# !python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !python -m pip install tensorboard==2.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For automatic file reloading as usual\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning==1.6.0\n",
      "  Using cached pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Using cached torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting numpy>=1.17.2\n",
      "  Using cached numpy-1.23.0-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\atula\\.conda\\envs\\i2dl\\lib\\site-packages)\n",
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wheel.exe is installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\atula\\.conda\\envs\\i2dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\atula\\.conda\\envs\\i2dl\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch>=1.8.*\n",
      "  Using cached torch-1.11.0-cp310-cp310-win_amd64.whl (158.0 MB)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting packaging>=17.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Using cached fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.1-cp310-cp310-win_amd64.whl (555 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.47.0-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.8.0-py2.py3-none-any.whl (164 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached setuptools-62.6.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting six>=1.9.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp310-cp310-win_amd64.whl (122 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, six, rsa, requests, pyasn1-modules, oauthlib, multidict, frozenlist, cachetools, yarl, typing-extensions, requests-oauthlib, pyparsing, google-auth, attrs, async-timeout, aiosignal, wheel, werkzeug, torch, tensorboard-plugin-wit, tensorboard-data-server, setuptools, protobuf, packaging, numpy, markdown, grpcio, google-auth-oauthlib, fsspec, colorama, aiohttp, absl-py, tqdm, torchmetrics, tensorboard, PyYAML, pyDeprecate, pytorch-lightning\n",
      "Successfully installed PyYAML-6.0 absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 attrs-21.4.0 cachetools-5.2.0 certifi-2022.6.15 charset-normalizer-2.0.12 colorama-0.4.5 frozenlist-1.3.0 fsspec-2022.5.0 google-auth-2.8.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 idna-3.3 markdown-3.3.7 multidict-6.0.2 numpy-1.23.0 oauthlib-3.2.0 packaging-21.3 protobuf-3.19.4 pyDeprecate-0.3.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 pytorch-lightning-1.6.0 requests-2.28.0 requests-oauthlib-1.3.1 rsa-4.8 setuptools-62.6.0 six-1.16.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.11.0 torchmetrics-0.9.1 tqdm-4.64.0 typing-extensions-4.2.0 urllib3-1.26.9 werkzeug-2.1.2 wheel-0.37.1 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# For google colab\n",
    "# !python -m pip install pytorch-lightning==1.6.0 > /dev/null\n",
    "\n",
    "# For anaconda/regular python\n",
    "!{sys.executable} -m pip install --ignore-installed pytorch-lightning==1.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning version: 1.6.0\n",
      "Tensorboard version: 2.9.1\n",
      "You are using an another version of Tensorboard. We expect Tensorboard 2.8 You may continue using your version but it might cause dependency and compatibility issues.\n",
      "PyTorch version Installed: 1.11.0+cpu\n",
      "Torchvision version Installed: 0.12.0+cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "print(f\"Lightning version: {pl.__version__}\")\n",
    "if not pl.__version__.startswith(\"1.6\"):\n",
    "    print(\"You are using another version of pytorch lightning. We expect pytorch lightning 1.6.0. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "\n",
    "import tensorboard\n",
    "import torch\n",
    "import torchvision\n",
    "print(f\"Tensorboard version: {tensorboard.__version__}\")\n",
    "if not tensorboard.__version__.startswith(\"2.8\"):\n",
    "    print(\"You are using an another version of Tensorboard. We expect Tensorboard 2.8 You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "print(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\n",
    "if not torch.__version__.startswith(\"1.11\"):\n",
    "    print(\"you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "if not torchvision.__version__.startswith(\"0.12\"):\n",
    "    print(\"you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Idea behind PyTorch Lightning\n",
    "\n",
    "Codes in a Deep learning project consists of three main categories:\n",
    "\n",
    "1. **Research code**   \n",
    "    This is the exciting part of the experiment where you configure the model architecture and try out different optimizers and target task. This is managed by the `LightningModule` of PyTorch Lightning.\n",
    "    \n",
    "2. **Engineering code**  \n",
    "    This is the same set of code that remain the same for all deep learning projects.Recall the training block of previous notebooks where we loop through the epochs and mini-batches. The `Trainer` class of PyTorch Lightning takes care of this part of code.\n",
    "    \n",
    "3. **Non-essential code**\n",
    "    It is very important that we log our training metrics and organize different training runs to have purposeful experimentation of models. The `Callbacks` class PyTorch Lightning helps us with this section. \n",
    "\n",
    "Let's look at each of these modules in detail.\n",
    "\n",
    "1. **LightningModules** contain all model related code. This is the part where we are working on when creating a new project. The idea is to have all important code in one module, e.g., the model's architecture and the evaluation of training and validation metrics. This provides a better overview as repeated elements, such as the training procedure, are not stored in the code that we work on. The lightning module also handles the calls `.to(device)` or `.train()` and `.eval()`. Hence, there is no need anymore to switch between the cpu and gpu and to take care of the model's mode as this is automated by the LightningModule. The framework also enables easy parallel computation on multiple gpus. \n",
    "\n",
    "2. **Trainer** contains all code needed for training our neural networks that doesn't change for each project (\"one size fits all\"). Usually, we don't touch the code automated by this class. The arguments that are specific for one training such as learning rate and batch size are provided as initialization arguments for the LightningModule.\n",
    "\n",
    "3. **Callbacks** automate all parts needed for logging hyperparameters or training results such as the tensorboard logger. Logging becomes very important for research later since the results of experiments need to be reproducible.\n",
    "\n",
    "All in all, PyTorch is a framework that handles all (annoying) \"engineering\" stuff for you such that you have more time for exciting research and scientific coding. This also results in the advantage that automated parts are guaranteed to be bug-free. Hence, you can't include a bug in a part of your code that is often used but not often checked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Overview of the PyTorch Lightning code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research relevant code goes into the `LightningModule`. The advantage is that we have all the model building, training & validation steps within a single class. These are the components that usually change based on the projects and tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorBoard Interface](./images/pl_quick_start_full_compressed.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining code is automated by the `Trainer` class which takes care of the tasks of our mechanical training loops components such as iterating through the minibatches and gradient updating steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/700/1*b81_j__xv8M0Bb6nFTXbAA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could already see how much more readable and concise our code is, after being transformed by PyTorch Lightning.\n",
    "\n",
    "Let us now train a neural network model with PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training with PyTorch Lightning\n",
    "\n",
    "We will build a two-layer neural network to train on the the [`Fashion-MNIST`](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) dataset for this notebook. \n",
    "\n",
    "## 4.1 Define A LightningModule\n",
    "\n",
    "We define our network as an instance of `pl.LightningModule` which replaces our `PyTorch` network based on the class `nn.Module`. Additionally, it contains all the relevant parts that are used for training and evaluating different models on various tasks.  \n",
    "\n",
    "Let's have a look at the implementation of `TwoLayerNet` in `exercise_code.lightning_models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__init__()` and `forward()` function defining the forward  pass remain the same. Hence, we can just copy the code from the `nn.Module`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class TwoLayerNet(pl.LightningModule):\n",
    "    def __init__(self, hparams, input_size=1 * 28 * 28, hidden_size=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the image  before sending as input to the model\n",
    "        N, _, _, _ = x.shape\n",
    "        x = x.view(N, -1)\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define the training  and validation steps since they also vary with different tasks and projects. Consequently, it is useful to integrate these parts into our instance of `LightningModule`. Validation loss is returned for each validation mini-batch and averaged at the end of the epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "\n",
    "        # Perform a forward pass on the network with inputs\n",
    "        out = self.forward(images)\n",
    "\n",
    "        # calculate the loss with the network predictions and ground truth targets\n",
    "        loss = F.cross_entropy(out, targets)\n",
    "\n",
    "        # Find the predicted class from probabilities of the image belonging to each of the classes\n",
    "        # from the network output\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        # Calculate the accuracy of predictions\n",
    "        acc = preds.eq(targets).sum().float() / targets.size(0)\n",
    "\n",
    "        # Log the accuracy and loss values to the tensorboard\n",
    "        self.log('loss', loss)\n",
    "        self.log('acc', acc)\n",
    "\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "\n",
    "        # Perform a forward pass on the network with inputs\n",
    "        out = self.forward(images)\n",
    "\n",
    "        # calculate the loss with the network predictions and ground truth targets\n",
    "        loss = F.cross_entropy(out, targets)\n",
    "\n",
    "        # Find the predicted class from probabilities of the image belonging to each of the classes\n",
    "        # from the network output\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        # Calculate the accuracy of predictions\n",
    "        acc = preds.eq(targets).sum().float() / targets.size(0)\n",
    "\n",
    "        # Visualise the predictions  of the model\n",
    "        if batch_idx == 0:\n",
    "            self.visualize_predictions(images, out.detach(), targets)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        # Average the loss over the entire validation data from it's mini-batches\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "\n",
    "        # Log the validation accuracy and loss values to the tensorboard\n",
    "        self.log('val_loss', avg_loss)\n",
    "        self.log('val_acc', avg_acc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step missing in our `LightningModule` is the optimizer. This method needs to be defined in every `LightningModule`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.model.parameters(), self.hparams[\"learning_rate\"], momentum=0.9)\n",
    "\n",
    "        return optim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set up the model and the training steps, we will now establish the data pipeline. PyTorch Lightning provides the `LightningDataModule` for setting up the dataloaders.\n",
    "\n",
    "Let's have a look at the implementation of `FashionMNISTDataModule` in `exercise_code.data_class`.\n",
    "\n",
    "The `prepare_data()` function intends to set up the dataset and the related transforms for it. As previously, we download the `FashionMNIST` dataset using `torchvision` and split the total training data into a training and validation set for tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class FashionMNISTDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, batch_size=4):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "\n",
    "        # Define the transform\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        # Download the Fashion-MNIST dataset\n",
    "        fashion_mnist_train_val = torchvision.datasets.FashionMNIST(root='../datasets', train=True,\n",
    "                                                                   download=True, transform=transform)\n",
    "\n",
    "        self.fashion_mnist_test = torchvision.datasets.FashionMNIST(root='../datasets', train=False,\n",
    "                                                                 download=True, transform=transform)\n",
    "\n",
    "        # Apply the Transforms\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        # Perform the training and validation split\n",
    "        self.train_dataset, self.val_dataset = random_split(\n",
    "            fashion_mnist_train_val, [50000, 10000])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now define `Dataloaders` for each of the data-splits. These data loaders can be directly called during model training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.fashion_mnist_test, batch_size=self.batch_size)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice now that most of the code of these steps can be directly copied from a Vanilla PyTorch code. Lightning just rearranges them. This marks the end of the research part of the code.\n",
    "\n",
    "Let's see now how the `Trainer` class works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.2 Fitting the model with a Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize the model and the data  with a set of hyperparameters given in the dictionary `hparams`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "\n",
    "from exercise_code.lightning_models import TwoLayerNet\n",
    "from exercise_code.data_class import FashionMNISTDataModule\n",
    "\n",
    "hparams = {\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"input_size\": 1 * 28 * 28,\n",
    "    \"hidden_size\": 512,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_workers\": 2,    # used by the dataloader, more workers means faster data preparation, but for us this is not a bottleneck here\n",
    "}\n",
    "\n",
    "\n",
    "model = TwoLayerNet(hparams)\n",
    "data=FashionMNISTDataModule(hparams)\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PyTorch Lightning provides ample flexibility for training using [`Trainer`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html) class.\n",
    "Have a look at the documentation to know more about them!\n",
    "\n",
    "Let's initialize it now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    # Uncomment to use GPU if available, if multiple you can select all indices, otherwise we use the first, -1 is CPU\n",
    "    # devices='0' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `max_epochs` sets the maximum number of epochs for training. \n",
    "The argument `weights_summary` prints a summary of the number of weights per layer at the beginning of the training. Set it to None if the summary is not required.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the actual training cell. The [`fit`](https://pytorch-lightning.readthedocs.io/en/latest/_modules/pytorch_lightning/trainer/trainer.html#Trainer.fit) function takes in the model and data to train the model with a lot more optional arguments for customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: C:\\Users\\atula\\Downloads\\exercise_07\\exercise_07\\lightning_logs\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 407 K \n",
      "-------------------------------------\n",
      "407 K     Trainable params\n",
      "0         Non-trainable params\n",
      "407 K     Total params\n",
      "1.628     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atula\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|██████████████████████████████▊      | 3125/3750 [02:16<00:27, 22.88it/s, loss=0.643, v_num=0, acc=0.688]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                 | 0/625 [00:02<?, ?it/s]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3126/3750 [02:20<00:28, 22.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3127/3750 [02:20<00:27, 22.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3128/3750 [02:20<00:27, 22.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3129/3750 [02:20<00:27, 22.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▉      | 3130/3750 [02:20<00:27, 22.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▉      | 3131/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3132/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3133/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3134/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3135/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3136/3750 [02:20<00:27, 22.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3137/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3138/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3139/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3140/3750 [02:20<00:27, 22.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3141/3750 [02:20<00:27, 22.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3142/3750 [02:20<00:27, 22.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3143/3750 [02:20<00:27, 22.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3144/3750 [02:20<00:27, 22.30it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3145/3750 [02:21<00:27, 22.30it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3146/3750 [02:21<00:27, 22.31it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3147/3750 [02:21<00:27, 22.31it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3148/3750 [02:21<00:26, 22.31it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3149/3750 [02:21<00:26, 22.32it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3150/3750 [02:21<00:26, 22.32it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3151/3750 [02:21<00:26, 22.32it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3152/3750 [02:21<00:26, 22.33it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3153/3750 [02:21<00:26, 22.33it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3154/3750 [02:21<00:26, 22.33it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3155/3750 [02:21<00:26, 22.34it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3156/3750 [02:21<00:26, 22.34it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3157/3750 [02:21<00:26, 22.34it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3158/3750 [02:21<00:26, 22.34it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3159/3750 [02:21<00:26, 22.35it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3160/3750 [02:21<00:26, 22.35it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3161/3750 [02:21<00:26, 22.35it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3162/3750 [02:21<00:26, 22.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3163/3750 [02:21<00:26, 22.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3164/3750 [02:21<00:26, 22.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3165/3750 [02:21<00:26, 22.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3166/3750 [02:21<00:26, 22.37it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3167/3750 [02:21<00:26, 22.37it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▎     | 3168/3750 [02:21<00:26, 22.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3169/3750 [02:21<00:25, 22.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3170/3750 [02:21<00:25, 22.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3171/3750 [02:21<00:25, 22.39it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3172/3750 [02:21<00:25, 22.39it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3173/3750 [02:21<00:25, 22.39it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3174/3750 [02:21<00:25, 22.40it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3175/3750 [02:21<00:25, 22.40it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3176/3750 [02:21<00:25, 22.40it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3177/3750 [02:21<00:25, 22.41it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3178/3750 [02:21<00:25, 22.41it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3179/3750 [02:21<00:25, 22.41it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3180/3750 [02:21<00:25, 22.42it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3181/3750 [02:21<00:25, 22.42it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3182/3750 [02:21<00:25, 22.43it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3183/3750 [02:21<00:25, 22.43it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3184/3750 [02:21<00:25, 22.43it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3185/3750 [02:21<00:25, 22.44it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3186/3750 [02:21<00:25, 22.44it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3187/3750 [02:21<00:25, 22.44it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3188/3750 [02:22<00:25, 22.45it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3189/3750 [02:22<00:24, 22.45it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|███████████████████████████████▍     | 3190/3750 [02:22<00:24, 22.45it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3191/3750 [02:22<00:24, 22.46it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3192/3750 [02:22<00:24, 22.46it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3193/3750 [02:22<00:24, 22.47it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3194/3750 [02:22<00:24, 22.47it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3195/3750 [02:22<00:24, 22.47it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3196/3750 [02:22<00:24, 22.48it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3197/3750 [02:22<00:24, 22.48it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3198/3750 [02:22<00:24, 22.49it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3199/3750 [02:22<00:24, 22.49it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3200/3750 [02:22<00:24, 22.49it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3201/3750 [02:22<00:24, 22.50it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3202/3750 [02:22<00:24, 22.50it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3203/3750 [02:22<00:24, 22.51it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3204/3750 [02:22<00:24, 22.51it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3205/3750 [02:22<00:24, 22.51it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▋     | 3206/3750 [02:22<00:24, 22.51it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3207/3750 [02:22<00:24, 22.52it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3208/3750 [02:22<00:24, 22.52it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3209/3750 [02:22<00:24, 22.52it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3210/3750 [02:22<00:23, 22.53it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3211/3750 [02:22<00:23, 22.53it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3212/3750 [02:22<00:23, 22.53it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3213/3750 [02:22<00:23, 22.54it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3214/3750 [02:22<00:23, 22.53it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3215/3750 [02:22<00:23, 22.53it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3216/3750 [02:22<00:23, 22.54it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3217/3750 [02:22<00:23, 22.54it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3218/3750 [02:22<00:23, 22.54it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3219/3750 [02:22<00:23, 22.55it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3220/3750 [02:22<00:23, 22.55it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3221/3750 [02:22<00:23, 22.56it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3222/3750 [02:22<00:23, 22.56it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3223/3750 [02:22<00:23, 22.56it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3224/3750 [02:22<00:23, 22.57it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3225/3750 [02:22<00:23, 22.57it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3226/3750 [02:22<00:23, 22.57it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3227/3750 [02:22<00:23, 22.58it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3228/3750 [02:22<00:23, 22.58it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3229/3750 [02:22<00:23, 22.59it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3230/3750 [02:22<00:23, 22.59it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3231/3750 [02:23<00:22, 22.59it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3232/3750 [02:23<00:22, 22.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3233/3750 [02:23<00:22, 22.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3234/3750 [02:23<00:22, 22.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3235/3750 [02:23<00:22, 22.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3236/3750 [02:23<00:22, 22.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3237/3750 [02:23<00:22, 22.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3238/3750 [02:23<00:22, 22.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3239/3750 [02:23<00:22, 22.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3240/3750 [02:23<00:22, 22.63it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3241/3750 [02:23<00:22, 22.63it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3242/3750 [02:23<00:22, 22.63it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3243/3750 [02:23<00:22, 22.64it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3244/3750 [02:23<00:22, 22.64it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3245/3750 [02:23<00:22, 22.65it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3246/3750 [02:23<00:22, 22.65it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3247/3750 [02:23<00:22, 22.65it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3248/3750 [02:23<00:22, 22.66it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3249/3750 [02:23<00:22, 22.66it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3250/3750 [02:23<00:22, 22.66it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3251/3750 [02:23<00:22, 22.67it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3252/3750 [02:23<00:21, 22.67it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3253/3750 [02:23<00:21, 22.67it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3254/3750 [02:23<00:21, 22.68it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3255/3750 [02:23<00:21, 22.68it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  87%|████████████████████████████████▏    | 3256/3750 [02:23<00:21, 22.68it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3257/3750 [02:23<00:21, 22.69it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3258/3750 [02:23<00:21, 22.69it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3259/3750 [02:23<00:21, 22.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3260/3750 [02:23<00:21, 22.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3261/3750 [02:23<00:21, 22.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3262/3750 [02:23<00:21, 22.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3263/3750 [02:23<00:21, 22.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3264/3750 [02:23<00:21, 22.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3265/3750 [02:23<00:21, 22.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3266/3750 [02:23<00:21, 22.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3267/3750 [02:23<00:21, 22.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3268/3750 [02:23<00:21, 22.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3269/3750 [02:23<00:21, 22.72it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3270/3750 [02:23<00:21, 22.72it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3271/3750 [02:23<00:21, 22.72it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3272/3750 [02:23<00:21, 22.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3273/3750 [02:23<00:20, 22.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3274/3750 [02:24<00:20, 22.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3275/3750 [02:24<00:20, 22.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3276/3750 [02:24<00:20, 22.74it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3277/3750 [02:24<00:20, 22.74it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3278/3750 [02:24<00:20, 22.74it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3279/3750 [02:24<00:20, 22.75it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3280/3750 [02:24<00:20, 22.75it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3281/3750 [02:24<00:20, 22.75it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3282/3750 [02:24<00:20, 22.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3283/3750 [02:24<00:20, 22.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3284/3750 [02:24<00:20, 22.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3285/3750 [02:24<00:20, 22.77it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3286/3750 [02:24<00:20, 22.77it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3287/3750 [02:24<00:20, 22.77it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3288/3750 [02:24<00:20, 22.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3289/3750 [02:24<00:20, 22.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3290/3750 [02:24<00:20, 22.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3291/3750 [02:24<00:20, 22.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3292/3750 [02:24<00:20, 22.79it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3293/3750 [02:24<00:20, 22.79it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3294/3750 [02:24<00:20, 22.79it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3295/3750 [02:24<00:19, 22.80it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3296/3750 [02:24<00:19, 22.80it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3297/3750 [02:24<00:19, 22.80it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3298/3750 [02:24<00:19, 22.81it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3299/3750 [02:24<00:19, 22.81it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3300/3750 [02:24<00:19, 22.81it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3301/3750 [02:24<00:19, 22.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3302/3750 [02:24<00:19, 22.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3303/3750 [02:24<00:19, 22.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3304/3750 [02:24<00:19, 22.83it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3305/3750 [02:24<00:19, 22.83it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3306/3750 [02:24<00:19, 22.83it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3307/3750 [02:24<00:19, 22.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3308/3750 [02:24<00:19, 22.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3309/3750 [02:24<00:19, 22.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3310/3750 [02:24<00:19, 22.85it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3311/3750 [02:24<00:19, 22.85it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3312/3750 [02:24<00:19, 22.86it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3313/3750 [02:24<00:19, 22.86it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3314/3750 [02:24<00:19, 22.86it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3315/3750 [02:24<00:19, 22.87it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3316/3750 [02:24<00:18, 22.87it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3317/3750 [02:25<00:18, 22.87it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3318/3750 [02:25<00:18, 22.88it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▋    | 3319/3750 [02:25<00:18, 22.88it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3320/3750 [02:25<00:18, 22.88it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3321/3750 [02:25<00:18, 22.89it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  89%|████████████████████████████████▊    | 3322/3750 [02:25<00:18, 22.89it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3323/3750 [02:25<00:18, 22.90it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3324/3750 [02:25<00:18, 22.90it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3325/3750 [02:25<00:18, 22.90it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3326/3750 [02:25<00:18, 22.91it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3327/3750 [02:25<00:18, 22.91it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3328/3750 [02:25<00:18, 22.91it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3329/3750 [02:25<00:18, 22.92it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3330/3750 [02:25<00:18, 22.92it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3331/3750 [02:25<00:18, 22.92it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3332/3750 [02:25<00:18, 22.93it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3333/3750 [02:25<00:18, 22.93it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3334/3750 [02:25<00:18, 22.93it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3335/3750 [02:25<00:18, 22.94it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3336/3750 [02:25<00:18, 22.94it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3337/3750 [02:25<00:18, 22.94it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3338/3750 [02:25<00:17, 22.95it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3339/3750 [02:25<00:17, 22.95it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3340/3750 [02:25<00:17, 22.95it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3341/3750 [02:25<00:17, 22.96it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3342/3750 [02:25<00:17, 22.96it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3343/3750 [02:25<00:17, 22.96it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3344/3750 [02:25<00:17, 22.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3345/3750 [02:25<00:17, 22.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3346/3750 [02:25<00:17, 22.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3347/3750 [02:25<00:17, 22.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3348/3750 [02:25<00:17, 22.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3349/3750 [02:25<00:17, 22.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3350/3750 [02:25<00:17, 22.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3351/3750 [02:25<00:17, 22.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3352/3750 [02:25<00:17, 22.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3353/3750 [02:25<00:17, 23.00it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3354/3750 [02:25<00:17, 23.00it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3355/3750 [02:25<00:17, 23.01it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3356/3750 [02:25<00:17, 23.01it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████    | 3357/3750 [02:25<00:17, 23.01it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3358/3750 [02:25<00:17, 23.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3359/3750 [02:25<00:16, 23.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3360/3750 [02:25<00:16, 23.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3361/3750 [02:25<00:16, 23.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3362/3750 [02:25<00:16, 23.03it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3363/3750 [02:26<00:16, 23.03it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3364/3750 [02:26<00:16, 23.03it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3365/3750 [02:26<00:16, 23.03it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3366/3750 [02:26<00:16, 23.04it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3367/3750 [02:26<00:16, 23.04it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3368/3750 [02:26<00:16, 23.04it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3369/3750 [02:26<00:16, 23.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3370/3750 [02:26<00:16, 23.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3371/3750 [02:26<00:16, 23.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3372/3750 [02:26<00:16, 23.06it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3373/3750 [02:26<00:16, 23.06it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3374/3750 [02:26<00:16, 23.07it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3375/3750 [02:26<00:16, 23.07it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3376/3750 [02:26<00:16, 23.07it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3377/3750 [02:26<00:16, 23.07it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3378/3750 [02:26<00:16, 23.07it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3379/3750 [02:26<00:16, 23.08it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3380/3750 [02:26<00:16, 23.08it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3381/3750 [02:26<00:15, 23.08it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3382/3750 [02:26<00:15, 23.08it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3383/3750 [02:26<00:15, 23.09it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3384/3750 [02:26<00:15, 23.09it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3385/3750 [02:26<00:15, 23.10it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3386/3750 [02:26<00:15, 23.10it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3387/3750 [02:26<00:15, 23.10it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|█████████████████████████████████▍   | 3388/3750 [02:26<00:15, 23.11it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3389/3750 [02:26<00:15, 23.11it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3390/3750 [02:26<00:15, 23.11it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3391/3750 [02:26<00:15, 23.11it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3392/3750 [02:26<00:15, 23.11it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3393/3750 [02:26<00:15, 23.12it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▍   | 3394/3750 [02:26<00:15, 23.12it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▍   | 3395/3750 [02:26<00:15, 23.12it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3396/3750 [02:26<00:15, 23.13it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3397/3750 [02:26<00:15, 23.13it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3398/3750 [02:26<00:15, 23.13it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3399/3750 [02:26<00:15, 23.14it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3400/3750 [02:26<00:15, 23.14it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3401/3750 [02:26<00:15, 23.14it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3402/3750 [02:26<00:15, 23.15it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3403/3750 [02:26<00:14, 23.15it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3404/3750 [02:27<00:14, 23.15it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3405/3750 [02:27<00:14, 23.15it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3406/3750 [02:27<00:14, 23.16it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3407/3750 [02:27<00:14, 23.16it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3408/3750 [02:27<00:14, 23.16it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3409/3750 [02:27<00:14, 23.17it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3410/3750 [02:27<00:14, 23.17it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3411/3750 [02:27<00:14, 23.17it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3412/3750 [02:27<00:14, 23.18it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3413/3750 [02:27<00:14, 23.18it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3414/3750 [02:27<00:14, 23.18it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3415/3750 [02:27<00:14, 23.19it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3416/3750 [02:27<00:14, 23.19it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3417/3750 [02:27<00:14, 23.19it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3418/3750 [02:27<00:14, 23.19it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3419/3750 [02:27<00:14, 23.19it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3420/3750 [02:27<00:14, 23.20it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3421/3750 [02:27<00:14, 23.20it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3422/3750 [02:27<00:14, 23.20it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3423/3750 [02:27<00:14, 23.21it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3424/3750 [02:27<00:14, 23.21it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3425/3750 [02:27<00:14, 23.21it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3426/3750 [02:27<00:13, 23.22it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3427/3750 [02:27<00:13, 23.22it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3428/3750 [02:27<00:13, 23.22it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3429/3750 [02:27<00:13, 23.22it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3430/3750 [02:27<00:13, 23.22it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3431/3750 [02:27<00:13, 23.22it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▊   | 3432/3750 [02:27<00:13, 23.23it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▊   | 3433/3750 [02:27<00:13, 23.23it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3434/3750 [02:27<00:13, 23.23it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3435/3750 [02:27<00:13, 23.24it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3436/3750 [02:27<00:13, 23.24it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3437/3750 [02:27<00:13, 23.24it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3438/3750 [02:27<00:13, 23.25it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3439/3750 [02:27<00:13, 23.25it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3440/3750 [02:27<00:13, 23.25it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3441/3750 [02:27<00:13, 23.26it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3442/3750 [02:27<00:13, 23.26it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3443/3750 [02:27<00:13, 23.26it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3444/3750 [02:28<00:13, 23.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3445/3750 [02:28<00:13, 23.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3446/3750 [02:28<00:13, 23.27it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3447/3750 [02:28<00:13, 23.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3448/3750 [02:28<00:12, 23.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3449/3750 [02:28<00:12, 23.28it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3450/3750 [02:28<00:12, 23.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3451/3750 [02:28<00:12, 23.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3452/3750 [02:28<00:12, 23.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3453/3750 [02:28<00:12, 23.29it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|██████████████████████████████████   | 3454/3750 [02:28<00:12, 23.30it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3455/3750 [02:28<00:12, 23.30it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3456/3750 [02:28<00:12, 23.30it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3457/3750 [02:28<00:12, 23.31it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3458/3750 [02:28<00:12, 23.31it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3459/3750 [02:28<00:12, 23.31it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3460/3750 [02:28<00:12, 23.31it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3461/3750 [02:28<00:12, 23.32it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3462/3750 [02:28<00:12, 23.32it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3463/3750 [02:28<00:12, 23.32it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3464/3750 [02:28<00:12, 23.33it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3465/3750 [02:28<00:12, 23.33it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3466/3750 [02:28<00:12, 23.33it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3467/3750 [02:28<00:12, 23.34it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3468/3750 [02:28<00:12, 23.34it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▏  | 3469/3750 [02:28<00:12, 23.34it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▏  | 3470/3750 [02:28<00:11, 23.35it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▏  | 3471/3750 [02:28<00:11, 23.35it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3472/3750 [02:28<00:11, 23.35it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3473/3750 [02:28<00:11, 23.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3474/3750 [02:28<00:11, 23.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3475/3750 [02:28<00:11, 23.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3476/3750 [02:28<00:11, 23.36it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3477/3750 [02:28<00:11, 23.37it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3478/3750 [02:28<00:11, 23.37it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3479/3750 [02:28<00:11, 23.37it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3480/3750 [02:28<00:11, 23.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3481/3750 [02:28<00:11, 23.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3482/3750 [02:28<00:11, 23.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3483/3750 [02:28<00:11, 23.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3484/3750 [02:28<00:11, 23.38it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3485/3750 [02:29<00:11, 23.39it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3486/3750 [02:29<00:11, 23.39it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3487/3750 [02:29<00:11, 23.39it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3488/3750 [02:29<00:11, 23.39it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3489/3750 [02:29<00:11, 23.40it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3490/3750 [02:29<00:11, 23.40it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3491/3750 [02:29<00:11, 23.40it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3492/3750 [02:29<00:11, 23.40it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3493/3750 [02:29<00:10, 23.41it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3494/3750 [02:29<00:10, 23.41it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3495/3750 [02:29<00:10, 23.41it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3496/3750 [02:29<00:10, 23.42it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3497/3750 [02:29<00:10, 23.42it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3498/3750 [02:29<00:10, 23.42it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3499/3750 [02:29<00:10, 23.42it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3500/3750 [02:29<00:10, 23.43it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3501/3750 [02:29<00:10, 23.43it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3502/3750 [02:29<00:10, 23.43it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3503/3750 [02:29<00:10, 23.44it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3504/3750 [02:29<00:10, 23.44it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3505/3750 [02:29<00:10, 23.44it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3506/3750 [02:29<00:10, 23.45it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▌  | 3507/3750 [02:29<00:10, 23.45it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▌  | 3508/3750 [02:29<00:10, 23.45it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▌  | 3509/3750 [02:29<00:10, 23.46it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3510/3750 [02:29<00:10, 23.46it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3511/3750 [02:29<00:10, 23.46it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3512/3750 [02:29<00:10, 23.46it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3513/3750 [02:29<00:10, 23.47it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3514/3750 [02:29<00:10, 23.47it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3515/3750 [02:29<00:10, 23.47it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3516/3750 [02:29<00:09, 23.47it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3517/3750 [02:29<00:09, 23.48it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3518/3750 [02:29<00:09, 23.48it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3519/3750 [02:29<00:09, 23.48it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94%|██████████████████████████████████▋  | 3520/3750 [02:29<00:09, 23.48it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3521/3750 [02:29<00:09, 23.49it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3522/3750 [02:29<00:09, 23.49it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3523/3750 [02:29<00:09, 23.49it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3524/3750 [02:29<00:09, 23.50it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3525/3750 [02:30<00:09, 23.50it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3526/3750 [02:30<00:09, 23.50it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3527/3750 [02:30<00:09, 23.51it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3528/3750 [02:30<00:09, 23.51it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3529/3750 [02:30<00:09, 23.51it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3530/3750 [02:30<00:09, 23.52it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3531/3750 [02:30<00:09, 23.52it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3532/3750 [02:30<00:09, 23.52it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3533/3750 [02:30<00:09, 23.53it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3534/3750 [02:30<00:09, 23.53it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3535/3750 [02:30<00:09, 23.54it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3536/3750 [02:30<00:09, 23.54it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3537/3750 [02:30<00:09, 23.54it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3538/3750 [02:30<00:09, 23.55it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3539/3750 [02:30<00:08, 23.55it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3540/3750 [02:30<00:08, 23.55it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3541/3750 [02:30<00:08, 23.56it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3542/3750 [02:30<00:08, 23.56it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3543/3750 [02:30<00:08, 23.56it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3544/3750 [02:30<00:08, 23.56it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3545/3750 [02:30<00:08, 23.57it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3546/3750 [02:30<00:08, 23.57it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3547/3750 [02:30<00:08, 23.57it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3548/3750 [02:30<00:08, 23.58it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3549/3750 [02:30<00:08, 23.58it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3550/3750 [02:30<00:08, 23.58it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3551/3750 [02:30<00:08, 23.59it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3552/3750 [02:30<00:08, 23.59it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3553/3750 [02:30<00:08, 23.59it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3554/3750 [02:30<00:08, 23.59it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3555/3750 [02:30<00:08, 23.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3556/3750 [02:30<00:08, 23.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3557/3750 [02:30<00:08, 23.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3558/3750 [02:30<00:08, 23.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3559/3750 [02:30<00:08, 23.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3560/3750 [02:30<00:08, 23.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3561/3750 [02:30<00:08, 23.60it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3562/3750 [02:30<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3563/3750 [02:30<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3564/3750 [02:30<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3565/3750 [02:30<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3566/3750 [02:31<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3567/3750 [02:31<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3568/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3569/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3570/3750 [02:31<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3571/3750 [02:31<00:07, 23.61it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3572/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3573/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3574/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3575/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3576/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3577/3750 [02:31<00:07, 23.62it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3578/3750 [02:31<00:07, 23.63it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3579/3750 [02:31<00:07, 23.63it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3580/3750 [02:31<00:07, 23.63it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3581/3750 [02:31<00:07, 23.63it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3582/3750 [02:31<00:07, 23.64it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3583/3750 [02:31<00:07, 23.64it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3584/3750 [02:31<00:07, 23.64it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3585/3750 [02:31<00:06, 23.64it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  96%|███████████████████████████████████▍ | 3586/3750 [02:31<00:06, 23.65it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3587/3750 [02:31<00:06, 23.65it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3588/3750 [02:31<00:06, 23.65it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3589/3750 [02:31<00:06, 23.65it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3590/3750 [02:31<00:06, 23.66it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3591/3750 [02:31<00:06, 23.66it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3592/3750 [02:31<00:06, 23.66it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3593/3750 [02:31<00:06, 23.67it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3594/3750 [02:31<00:06, 23.67it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3595/3750 [02:31<00:06, 23.67it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3596/3750 [02:31<00:06, 23.67it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3597/3750 [02:31<00:06, 23.68it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3598/3750 [02:31<00:06, 23.68it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3599/3750 [02:31<00:06, 23.68it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3600/3750 [02:32<00:06, 23.68it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3601/3750 [02:32<00:06, 23.69it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3602/3750 [02:32<00:06, 23.69it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3603/3750 [02:32<00:06, 23.69it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3604/3750 [02:32<00:06, 23.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3605/3750 [02:32<00:06, 23.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3606/3750 [02:32<00:06, 23.70it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3607/3750 [02:32<00:06, 23.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3608/3750 [02:32<00:05, 23.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3609/3750 [02:32<00:05, 23.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3610/3750 [02:32<00:05, 23.71it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3611/3750 [02:32<00:05, 23.72it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3612/3750 [02:32<00:05, 23.72it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3613/3750 [02:32<00:05, 23.72it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3614/3750 [02:32<00:05, 23.72it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3615/3750 [02:32<00:05, 23.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3616/3750 [02:32<00:05, 23.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3617/3750 [02:32<00:05, 23.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3618/3750 [02:32<00:05, 23.73it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3619/3750 [02:32<00:05, 23.74it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3620/3750 [02:32<00:05, 23.74it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3621/3750 [02:32<00:05, 23.74it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3622/3750 [02:32<00:05, 23.74it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3623/3750 [02:32<00:05, 23.75it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3624/3750 [02:32<00:05, 23.75it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3625/3750 [02:32<00:05, 23.75it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3626/3750 [02:32<00:05, 23.75it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3627/3750 [02:32<00:05, 23.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3628/3750 [02:32<00:05, 23.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3629/3750 [02:32<00:05, 23.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3630/3750 [02:32<00:05, 23.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3631/3750 [02:32<00:05, 23.76it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3632/3750 [02:32<00:04, 23.77it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3633/3750 [02:32<00:04, 23.77it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3634/3750 [02:32<00:04, 23.77it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3635/3750 [02:32<00:04, 23.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3636/3750 [02:32<00:04, 23.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3637/3750 [02:32<00:04, 23.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3638/3750 [02:32<00:04, 23.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3639/3750 [02:33<00:04, 23.78it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3640/3750 [02:33<00:04, 23.79it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3641/3750 [02:33<00:04, 23.79it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3642/3750 [02:33<00:04, 23.79it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3643/3750 [02:33<00:04, 23.79it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3644/3750 [02:33<00:04, 23.80it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3645/3750 [02:33<00:04, 23.80it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3646/3750 [02:33<00:04, 23.80it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3647/3750 [02:33<00:04, 23.81it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3648/3750 [02:33<00:04, 23.81it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3649/3750 [02:33<00:04, 23.81it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3650/3750 [02:33<00:04, 23.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3651/3750 [02:33<00:04, 23.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|████████████████████████████████████ | 3652/3750 [02:33<00:04, 23.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3653/3750 [02:33<00:04, 23.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3654/3750 [02:33<00:04, 23.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3655/3750 [02:33<00:03, 23.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3656/3750 [02:33<00:03, 23.82it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3657/3750 [02:33<00:03, 23.83it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3658/3750 [02:33<00:03, 23.83it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3659/3750 [02:33<00:03, 23.83it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3660/3750 [02:33<00:03, 23.83it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3661/3750 [02:33<00:03, 23.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3662/3750 [02:33<00:03, 23.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3663/3750 [02:33<00:03, 23.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3664/3750 [02:33<00:03, 23.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3665/3750 [02:33<00:03, 23.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3666/3750 [02:33<00:03, 23.84it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3667/3750 [02:33<00:03, 23.85it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3668/3750 [02:33<00:03, 23.85it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3669/3750 [02:33<00:03, 23.85it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3670/3750 [02:33<00:03, 23.86it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3671/3750 [02:33<00:03, 23.86it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3672/3750 [02:33<00:03, 23.86it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3673/3750 [02:33<00:03, 23.87it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3674/3750 [02:33<00:03, 23.87it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3675/3750 [02:33<00:03, 23.87it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3676/3750 [02:33<00:03, 23.88it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3677/3750 [02:33<00:03, 23.88it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3678/3750 [02:34<00:03, 23.88it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3679/3750 [02:34<00:02, 23.89it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3680/3750 [02:34<00:02, 23.89it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3681/3750 [02:34<00:02, 23.89it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3682/3750 [02:34<00:02, 23.89it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3683/3750 [02:34<00:02, 23.90it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3684/3750 [02:34<00:02, 23.90it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3685/3750 [02:34<00:02, 23.90it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3686/3750 [02:34<00:02, 23.91it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3687/3750 [02:34<00:02, 23.91it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3688/3750 [02:34<00:02, 23.91it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3689/3750 [02:34<00:02, 23.92it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3690/3750 [02:34<00:02, 23.92it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3691/3750 [02:34<00:02, 23.92it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3692/3750 [02:34<00:02, 23.93it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3693/3750 [02:34<00:02, 23.93it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3694/3750 [02:34<00:02, 23.93it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3695/3750 [02:34<00:02, 23.93it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3696/3750 [02:34<00:02, 23.94it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3697/3750 [02:34<00:02, 23.94it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3698/3750 [02:34<00:02, 23.94it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3699/3750 [02:34<00:02, 23.94it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3700/3750 [02:34<00:02, 23.95it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3701/3750 [02:34<00:02, 23.95it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3702/3750 [02:34<00:02, 23.95it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3703/3750 [02:34<00:01, 23.96it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3704/3750 [02:34<00:01, 23.96it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3705/3750 [02:34<00:01, 23.96it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3706/3750 [02:34<00:01, 23.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3707/3750 [02:34<00:01, 23.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3708/3750 [02:34<00:01, 23.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3709/3750 [02:34<00:01, 23.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3710/3750 [02:34<00:01, 23.97it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3711/3750 [02:34<00:01, 23.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3712/3750 [02:34<00:01, 23.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3713/3750 [02:34<00:01, 23.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3714/3750 [02:34<00:01, 23.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3715/3750 [02:34<00:01, 23.98it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3716/3750 [02:34<00:01, 23.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3717/3750 [02:34<00:01, 23.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|████████████████████████████████████▋| 3718/3750 [02:34<00:01, 23.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3719/3750 [02:35<00:01, 23.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3720/3750 [02:35<00:01, 23.99it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3721/3750 [02:35<00:01, 24.00it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3722/3750 [02:35<00:01, 24.00it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3723/3750 [02:35<00:01, 24.00it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3724/3750 [02:35<00:01, 24.01it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3725/3750 [02:35<00:01, 24.01it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3726/3750 [02:35<00:00, 24.01it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3727/3750 [02:35<00:00, 24.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3728/3750 [02:35<00:00, 24.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3729/3750 [02:35<00:00, 24.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3730/3750 [02:35<00:00, 24.02it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3731/3750 [02:35<00:00, 24.03it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3732/3750 [02:35<00:00, 24.03it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3733/3750 [02:35<00:00, 24.03it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3734/3750 [02:35<00:00, 24.04it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3735/3750 [02:35<00:00, 24.04it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3736/3750 [02:35<00:00, 24.04it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3737/3750 [02:35<00:00, 24.04it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3738/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3739/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3740/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3741/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3742/3750 [02:35<00:00, 24.06it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3743/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3744/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3745/3750 [02:35<00:00, 24.06it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3746/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3747/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3748/3750 [02:35<00:00, 24.05it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3749/3750 [02:35<00:00, 24.06it/s, loss=0.643, v_num=0, acc=0.688]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████| 3750/3750 [02:35<00:00, 24.06it/s, loss=0.643, v_num=0, acc=0.688, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  83%|█████████████████▌   | 3125/3750 [04:45<00:57, 10.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                 | 0/625 [00:03<?, ?it/s]\u001b[A\n",
      "Epoch 1:  83%|█████████████████▌   | 3126/3750 [04:50<00:58, 10.74it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  83%|█████████████████▌   | 3127/3750 [04:50<00:57, 10.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  83%|█████████████████▌   | 3128/3750 [04:51<00:57, 10.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  83%|█████████████████▌   | 3129/3750 [04:51<00:57, 10.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  83%|█████████████████▌   | 3130/3750 [04:51<00:57, 10.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  83%|█████████████████▌   | 3131/3750 [04:51<00:57, 10.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3132/3750 [04:51<00:57, 10.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3133/3750 [04:51<00:57, 10.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3134/3750 [04:51<00:57, 10.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3135/3750 [04:51<00:57, 10.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3136/3750 [04:51<00:57, 10.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3137/3750 [04:51<00:56, 10.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3138/3750 [04:51<00:56, 10.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3139/3750 [04:51<00:56, 10.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3140/3750 [04:51<00:56, 10.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3141/3750 [04:51<00:56, 10.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3142/3750 [04:51<00:56, 10.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3143/3750 [04:51<00:56, 10.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3144/3750 [04:51<00:56, 10.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3145/3750 [04:51<00:56, 10.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3146/3750 [04:51<00:55, 10.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▌   | 3147/3750 [04:51<00:55, 10.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3148/3750 [04:51<00:55, 10.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3149/3750 [04:51<00:55, 10.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3150/3750 [04:51<00:55, 10.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3151/3750 [04:51<00:55, 10.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3152/3750 [04:51<00:55, 10.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3153/3750 [04:51<00:55, 10.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3154/3750 [04:51<00:55, 10.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3155/3750 [04:51<00:55, 10.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3156/3750 [04:51<00:54, 10.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  84%|█████████████████▋   | 3157/3750 [04:51<00:54, 10.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3158/3750 [04:52<00:54, 10.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3159/3750 [04:52<00:54, 10.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3160/3750 [04:52<00:54, 10.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3161/3750 [04:52<00:54, 10.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3162/3750 [04:52<00:54, 10.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3163/3750 [04:52<00:54, 10.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3164/3750 [04:52<00:54, 10.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3165/3750 [04:52<00:54, 10.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3166/3750 [04:52<00:53, 10.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3167/3750 [04:52<00:53, 10.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  84%|█████████████████▋   | 3168/3750 [04:52<00:53, 10.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▋   | 3169/3750 [04:52<00:53, 10.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3170/3750 [04:52<00:53, 10.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3171/3750 [04:52<00:53, 10.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3172/3750 [04:52<00:53, 10.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3173/3750 [04:52<00:53, 10.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3174/3750 [04:52<00:53, 10.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3175/3750 [04:52<00:53, 10.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3176/3750 [04:52<00:52, 10.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3177/3750 [04:52<00:52, 10.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3178/3750 [04:52<00:52, 10.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3179/3750 [04:52<00:52, 10.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3180/3750 [04:52<00:52, 10.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3181/3750 [04:52<00:52, 10.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3182/3750 [04:52<00:52, 10.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3183/3750 [04:52<00:52, 10.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3184/3750 [04:52<00:52, 10.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3185/3750 [04:52<00:51, 10.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3186/3750 [04:53<00:51, 10.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3187/3750 [04:53<00:51, 10.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3188/3750 [04:53<00:51, 10.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3189/3750 [04:53<00:51, 10.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3190/3750 [04:53<00:51, 10.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▊   | 3191/3750 [04:53<00:51, 10.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3192/3750 [04:53<00:51, 10.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3193/3750 [04:53<00:51, 10.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3194/3750 [04:53<00:51, 10.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3195/3750 [04:53<00:50, 10.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3196/3750 [04:53<00:50, 10.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3197/3750 [04:53<00:50, 10.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3198/3750 [04:53<00:50, 10.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3199/3750 [04:53<00:50, 10.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3200/3750 [04:53<00:50, 10.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3201/3750 [04:53<00:50, 10.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3202/3750 [04:53<00:50, 10.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3203/3750 [04:53<00:50, 10.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3204/3750 [04:53<00:50, 10.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3205/3750 [04:53<00:49, 10.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  85%|█████████████████▉   | 3206/3750 [04:53<00:49, 10.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3207/3750 [04:53<00:49, 10.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3208/3750 [04:53<00:49, 10.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3209/3750 [04:53<00:49, 10.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3210/3750 [04:53<00:49, 10.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3211/3750 [04:53<00:49, 10.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3212/3750 [04:53<00:49, 10.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3213/3750 [04:53<00:49, 10.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|█████████████████▉   | 3214/3750 [04:53<00:49, 10.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3215/3750 [04:53<00:48, 10.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3216/3750 [04:53<00:48, 10.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3217/3750 [04:53<00:48, 10.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3218/3750 [04:54<00:48, 10.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3219/3750 [04:54<00:48, 10.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3220/3750 [04:54<00:48, 10.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3221/3750 [04:54<00:48, 10.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3222/3750 [04:54<00:48, 10.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  86%|██████████████████   | 3223/3750 [04:54<00:48, 10.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3224/3750 [04:54<00:47, 10.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3225/3750 [04:54<00:47, 10.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3226/3750 [04:54<00:47, 10.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3227/3750 [04:54<00:47, 10.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3228/3750 [04:54<00:47, 10.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3229/3750 [04:54<00:47, 10.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3230/3750 [04:54<00:47, 10.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3231/3750 [04:54<00:47, 10.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3232/3750 [04:54<00:47, 10.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3233/3750 [04:54<00:47, 10.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3234/3750 [04:54<00:46, 10.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3235/3750 [04:54<00:46, 10.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████   | 3236/3750 [04:54<00:46, 10.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▏  | 3237/3750 [04:54<00:46, 10.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▏  | 3238/3750 [04:54<00:46, 10.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▏  | 3239/3750 [04:54<00:46, 10.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▏  | 3240/3750 [04:54<00:46, 10.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▏  | 3241/3750 [04:54<00:46, 10.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▏  | 3242/3750 [04:54<00:46, 11.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▏  | 3243/3750 [04:54<00:46, 11.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3244/3750 [04:54<00:46, 11.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3245/3750 [04:54<00:45, 11.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3246/3750 [04:54<00:45, 11.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3247/3750 [04:55<00:45, 11.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3248/3750 [04:55<00:45, 11.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3249/3750 [04:55<00:45, 11.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3250/3750 [04:55<00:45, 11.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3251/3750 [04:55<00:45, 11.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3252/3750 [04:55<00:45, 11.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3253/3750 [04:55<00:45, 11.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3254/3750 [04:55<00:45, 11.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3255/3750 [04:55<00:44, 11.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3256/3750 [04:55<00:44, 11.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3257/3750 [04:55<00:44, 11.03it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▏  | 3258/3750 [04:55<00:44, 11.03it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3259/3750 [04:55<00:44, 11.03it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3260/3750 [04:55<00:44, 11.03it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3261/3750 [04:55<00:44, 11.04it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3262/3750 [04:55<00:44, 11.04it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3263/3750 [04:55<00:44, 11.04it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3264/3750 [04:55<00:44, 11.04it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3265/3750 [04:55<00:43, 11.04it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3266/3750 [04:55<00:43, 11.05it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3267/3750 [04:55<00:43, 11.05it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3268/3750 [04:55<00:43, 11.05it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3269/3750 [04:55<00:43, 11.05it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3270/3750 [04:55<00:43, 11.05it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3271/3750 [04:55<00:43, 11.06it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3272/3750 [04:55<00:43, 11.06it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3273/3750 [04:55<00:43, 11.06it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3274/3750 [04:55<00:43, 11.06it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3275/3750 [04:55<00:42, 11.07it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3276/3750 [04:55<00:42, 11.07it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3277/3750 [04:56<00:42, 11.07it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3278/3750 [04:56<00:42, 11.07it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3279/3750 [04:56<00:42, 11.07it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3280/3750 [04:56<00:42, 11.08it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  87%|██████████████████▎  | 3281/3750 [04:56<00:42, 11.08it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3282/3750 [04:56<00:42, 11.08it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3283/3750 [04:56<00:42, 11.08it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3284/3750 [04:56<00:42, 11.09it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3285/3750 [04:56<00:41, 11.09it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3286/3750 [04:56<00:41, 11.09it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3287/3750 [04:56<00:41, 11.09it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3288/3750 [04:56<00:41, 11.09it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88%|██████████████████▍  | 3289/3750 [04:56<00:41, 11.10it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3290/3750 [04:56<00:41, 11.10it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3291/3750 [04:56<00:41, 11.10it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3292/3750 [04:56<00:41, 11.10it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3293/3750 [04:56<00:41, 11.10it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3294/3750 [04:56<00:41, 11.10it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3295/3750 [04:56<00:40, 11.11it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3296/3750 [04:56<00:40, 11.11it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3297/3750 [04:56<00:40, 11.11it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3298/3750 [04:56<00:40, 11.11it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3299/3750 [04:56<00:40, 11.11it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3300/3750 [04:56<00:40, 11.12it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3301/3750 [04:56<00:40, 11.12it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3302/3750 [04:56<00:40, 11.12it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▍  | 3303/3750 [04:57<00:40, 11.12it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3304/3750 [04:57<00:40, 11.12it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3305/3750 [04:57<00:40, 11.12it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3306/3750 [04:57<00:39, 11.13it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3307/3750 [04:57<00:39, 11.13it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3308/3750 [04:57<00:39, 11.13it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3309/3750 [04:57<00:39, 11.13it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3310/3750 [04:57<00:39, 11.13it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3311/3750 [04:57<00:39, 11.14it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3312/3750 [04:57<00:39, 11.14it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3313/3750 [04:57<00:39, 11.14it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3314/3750 [04:57<00:39, 11.14it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3315/3750 [04:57<00:39, 11.14it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3316/3750 [04:57<00:38, 11.15it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3317/3750 [04:57<00:38, 11.15it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  88%|██████████████████▌  | 3318/3750 [04:57<00:38, 11.15it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▌  | 3319/3750 [04:57<00:38, 11.15it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▌  | 3320/3750 [04:57<00:38, 11.15it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▌  | 3321/3750 [04:57<00:38, 11.16it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▌  | 3322/3750 [04:57<00:38, 11.16it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▌  | 3323/3750 [04:57<00:38, 11.16it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▌  | 3324/3750 [04:57<00:38, 11.16it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▌  | 3325/3750 [04:57<00:38, 11.17it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3326/3750 [04:57<00:37, 11.17it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3327/3750 [04:57<00:37, 11.17it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3328/3750 [04:57<00:37, 11.17it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3329/3750 [04:57<00:37, 11.17it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3330/3750 [04:57<00:37, 11.18it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3331/3750 [04:57<00:37, 11.18it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3332/3750 [04:58<00:37, 11.18it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3333/3750 [04:58<00:37, 11.18it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3334/3750 [04:58<00:37, 11.19it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3335/3750 [04:58<00:37, 11.19it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3336/3750 [04:58<00:36, 11.19it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3337/3750 [04:58<00:36, 11.19it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3338/3750 [04:58<00:36, 11.19it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3339/3750 [04:58<00:36, 11.20it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3340/3750 [04:58<00:36, 11.20it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3341/3750 [04:58<00:36, 11.20it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3342/3750 [04:58<00:36, 11.20it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3343/3750 [04:58<00:36, 11.21it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3344/3750 [04:58<00:36, 11.21it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3345/3750 [04:58<00:36, 11.21it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3346/3750 [04:58<00:36, 11.21it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3347/3750 [04:58<00:35, 11.22it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▋  | 3348/3750 [04:58<00:35, 11.22it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▊  | 3349/3750 [04:58<00:35, 11.22it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▊  | 3350/3750 [04:58<00:35, 11.22it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▊  | 3351/3750 [04:58<00:35, 11.22it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▊  | 3352/3750 [04:58<00:35, 11.23it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▊  | 3353/3750 [04:58<00:35, 11.23it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▊  | 3354/3750 [04:58<00:35, 11.23it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89%|██████████████████▊  | 3355/3750 [04:58<00:35, 11.23it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  89%|██████████████████▊  | 3356/3750 [04:58<00:35, 11.24it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3357/3750 [04:58<00:34, 11.24it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3358/3750 [04:58<00:34, 11.24it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3359/3750 [04:58<00:34, 11.24it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3360/3750 [04:58<00:34, 11.24it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3361/3750 [04:58<00:34, 11.25it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3362/3750 [04:58<00:34, 11.25it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3363/3750 [04:58<00:34, 11.25it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3364/3750 [04:58<00:34, 11.25it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3365/3750 [04:58<00:34, 11.25it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3366/3750 [04:59<00:34, 11.26it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3367/3750 [04:59<00:34, 11.26it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3368/3750 [04:59<00:33, 11.26it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3369/3750 [04:59<00:33, 11.26it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▊  | 3370/3750 [04:59<00:33, 11.26it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3371/3750 [04:59<00:33, 11.26it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3372/3750 [04:59<00:33, 11.27it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3373/3750 [04:59<00:33, 11.27it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3374/3750 [04:59<00:33, 11.27it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3375/3750 [04:59<00:33, 11.27it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3376/3750 [04:59<00:33, 11.27it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3377/3750 [04:59<00:33, 11.28it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3378/3750 [04:59<00:32, 11.28it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3379/3750 [04:59<00:32, 11.28it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3380/3750 [04:59<00:32, 11.28it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3381/3750 [04:59<00:32, 11.28it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3382/3750 [04:59<00:32, 11.29it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3383/3750 [04:59<00:32, 11.29it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3384/3750 [04:59<00:32, 11.29it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3385/3750 [04:59<00:32, 11.29it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3386/3750 [04:59<00:32, 11.29it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3387/3750 [04:59<00:32, 11.29it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3388/3750 [04:59<00:32, 11.30it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3389/3750 [04:59<00:31, 11.30it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3390/3750 [04:59<00:31, 11.30it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3391/3750 [04:59<00:31, 11.30it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|██████████████████▉  | 3392/3750 [04:59<00:31, 11.31it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  90%|███████████████████  | 3393/3750 [05:00<00:31, 11.31it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3394/3750 [05:00<00:31, 11.31it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3395/3750 [05:00<00:31, 11.31it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3396/3750 [05:00<00:31, 11.32it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3397/3750 [05:00<00:31, 11.32it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3398/3750 [05:00<00:31, 11.32it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3399/3750 [05:00<00:30, 11.32it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3400/3750 [05:00<00:30, 11.33it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3401/3750 [05:00<00:30, 11.33it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3402/3750 [05:00<00:30, 11.33it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3403/3750 [05:00<00:30, 11.33it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3404/3750 [05:00<00:30, 11.33it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3405/3750 [05:00<00:30, 11.34it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3406/3750 [05:00<00:30, 11.34it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3407/3750 [05:00<00:30, 11.34it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3408/3750 [05:00<00:30, 11.34it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3409/3750 [05:00<00:30, 11.34it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3410/3750 [05:00<00:29, 11.35it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3411/3750 [05:00<00:29, 11.35it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3412/3750 [05:00<00:29, 11.35it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3413/3750 [05:00<00:29, 11.35it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3414/3750 [05:00<00:29, 11.35it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████  | 3415/3750 [05:00<00:29, 11.36it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3416/3750 [05:00<00:29, 11.36it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3417/3750 [05:00<00:29, 11.36it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3418/3750 [05:00<00:29, 11.36it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3419/3750 [05:00<00:29, 11.36it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3420/3750 [05:00<00:29, 11.37it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  91%|███████████████████▏ | 3421/3750 [05:00<00:28, 11.37it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3422/3750 [05:00<00:28, 11.37it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3423/3750 [05:00<00:28, 11.37it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3424/3750 [05:00<00:28, 11.38it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3425/3750 [05:01<00:28, 11.38it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3426/3750 [05:01<00:28, 11.38it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3427/3750 [05:01<00:28, 11.38it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3428/3750 [05:01<00:28, 11.39it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3429/3750 [05:01<00:28, 11.39it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3430/3750 [05:01<00:28, 11.39it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▏ | 3431/3750 [05:01<00:28, 11.39it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▏ | 3432/3750 [05:01<00:27, 11.39it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▏ | 3433/3750 [05:01<00:27, 11.40it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▏ | 3434/3750 [05:01<00:27, 11.40it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▏ | 3435/3750 [05:01<00:27, 11.40it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▏ | 3436/3750 [05:01<00:27, 11.40it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▏ | 3437/3750 [05:01<00:27, 11.40it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3438/3750 [05:01<00:27, 11.40it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3439/3750 [05:01<00:27, 11.41it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3440/3750 [05:01<00:27, 11.41it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3441/3750 [05:01<00:27, 11.41it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3442/3750 [05:01<00:26, 11.41it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3443/3750 [05:01<00:26, 11.41it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3444/3750 [05:01<00:26, 11.42it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3445/3750 [05:01<00:26, 11.42it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3446/3750 [05:01<00:26, 11.42it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3447/3750 [05:01<00:26, 11.42it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3448/3750 [05:01<00:26, 11.42it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3449/3750 [05:01<00:26, 11.43it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3450/3750 [05:01<00:26, 11.43it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3451/3750 [05:01<00:26, 11.43it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3452/3750 [05:01<00:26, 11.43it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3453/3750 [05:02<00:25, 11.43it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3454/3750 [05:02<00:25, 11.44it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3455/3750 [05:02<00:25, 11.44it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3456/3750 [05:02<00:25, 11.44it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3457/3750 [05:02<00:25, 11.44it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3458/3750 [05:02<00:25, 11.44it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▎ | 3459/3750 [05:02<00:25, 11.45it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3460/3750 [05:02<00:25, 11.45it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3461/3750 [05:02<00:25, 11.45it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3462/3750 [05:02<00:25, 11.45it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3463/3750 [05:02<00:25, 11.45it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3464/3750 [05:02<00:24, 11.46it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3465/3750 [05:02<00:24, 11.46it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3466/3750 [05:02<00:24, 11.46it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3467/3750 [05:02<00:24, 11.46it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  92%|███████████████████▍ | 3468/3750 [05:02<00:24, 11.47it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3469/3750 [05:02<00:24, 11.47it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3470/3750 [05:02<00:24, 11.47it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3471/3750 [05:02<00:24, 11.47it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3472/3750 [05:02<00:24, 11.48it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3473/3750 [05:02<00:24, 11.48it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3474/3750 [05:02<00:24, 11.48it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3475/3750 [05:02<00:23, 11.48it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3476/3750 [05:02<00:23, 11.48it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3477/3750 [05:02<00:23, 11.49it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3478/3750 [05:02<00:23, 11.49it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3479/3750 [05:02<00:23, 11.49it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3480/3750 [05:02<00:23, 11.49it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3481/3750 [05:02<00:23, 11.49it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▍ | 3482/3750 [05:02<00:23, 11.50it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3483/3750 [05:02<00:23, 11.50it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3484/3750 [05:02<00:23, 11.50it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3485/3750 [05:02<00:23, 11.50it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3486/3750 [05:02<00:22, 11.51it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  93%|███████████████████▌ | 3487/3750 [05:03<00:22, 11.51it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3488/3750 [05:03<00:22, 11.51it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3489/3750 [05:03<00:22, 11.51it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3490/3750 [05:03<00:22, 11.51it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3491/3750 [05:03<00:22, 11.52it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3492/3750 [05:03<00:22, 11.52it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3493/3750 [05:03<00:22, 11.52it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3494/3750 [05:03<00:22, 11.52it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3495/3750 [05:03<00:22, 11.52it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3496/3750 [05:03<00:22, 11.52it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3497/3750 [05:03<00:21, 11.53it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3498/3750 [05:03<00:21, 11.53it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3499/3750 [05:03<00:21, 11.53it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3500/3750 [05:03<00:21, 11.53it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3501/3750 [05:03<00:21, 11.53it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3502/3750 [05:03<00:21, 11.54it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3503/3750 [05:03<00:21, 11.54it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▌ | 3504/3750 [05:03<00:21, 11.54it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▋ | 3505/3750 [05:03<00:21, 11.54it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  93%|███████████████████▋ | 3506/3750 [05:03<00:21, 11.54it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3507/3750 [05:03<00:21, 11.54it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3508/3750 [05:03<00:20, 11.55it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3509/3750 [05:03<00:20, 11.55it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3510/3750 [05:03<00:20, 11.55it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3511/3750 [05:03<00:20, 11.55it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3512/3750 [05:03<00:20, 11.55it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3513/3750 [05:04<00:20, 11.55it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3514/3750 [05:04<00:20, 11.56it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3515/3750 [05:04<00:20, 11.56it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3516/3750 [05:04<00:20, 11.56it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3517/3750 [05:04<00:20, 11.56it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3518/3750 [05:04<00:20, 11.56it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3519/3750 [05:04<00:19, 11.57it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3520/3750 [05:04<00:19, 11.57it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3521/3750 [05:04<00:19, 11.57it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3522/3750 [05:04<00:19, 11.57it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3523/3750 [05:04<00:19, 11.58it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3524/3750 [05:04<00:19, 11.58it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3525/3750 [05:04<00:19, 11.58it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▋ | 3526/3750 [05:04<00:19, 11.58it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3527/3750 [05:04<00:19, 11.58it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3528/3750 [05:04<00:19, 11.59it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3529/3750 [05:04<00:19, 11.59it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3530/3750 [05:04<00:18, 11.59it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3531/3750 [05:04<00:18, 11.59it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3532/3750 [05:04<00:18, 11.59it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3533/3750 [05:04<00:18, 11.60it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3534/3750 [05:04<00:18, 11.60it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3535/3750 [05:04<00:18, 11.60it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3536/3750 [05:04<00:18, 11.60it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3537/3750 [05:04<00:18, 11.60it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3538/3750 [05:04<00:18, 11.61it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3539/3750 [05:04<00:18, 11.61it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3540/3750 [05:04<00:18, 11.61it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3541/3750 [05:04<00:17, 11.61it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3542/3750 [05:04<00:17, 11.61it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  94%|███████████████████▊ | 3543/3750 [05:04<00:17, 11.62it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▊ | 3544/3750 [05:05<00:17, 11.62it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▊ | 3545/3750 [05:05<00:17, 11.62it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▊ | 3546/3750 [05:05<00:17, 11.62it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▊ | 3547/3750 [05:05<00:17, 11.63it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▊ | 3548/3750 [05:05<00:17, 11.63it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▊ | 3549/3750 [05:05<00:17, 11.63it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3550/3750 [05:05<00:17, 11.63it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3551/3750 [05:05<00:17, 11.63it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3552/3750 [05:05<00:17, 11.64it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95%|███████████████████▉ | 3553/3750 [05:05<00:16, 11.64it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3554/3750 [05:05<00:16, 11.64it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3555/3750 [05:05<00:16, 11.64it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3556/3750 [05:05<00:16, 11.64it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3557/3750 [05:05<00:16, 11.65it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3558/3750 [05:05<00:16, 11.65it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3559/3750 [05:05<00:16, 11.65it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3560/3750 [05:05<00:16, 11.65it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3561/3750 [05:05<00:16, 11.65it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3562/3750 [05:05<00:16, 11.66it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3563/3750 [05:05<00:16, 11.66it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3564/3750 [05:05<00:15, 11.66it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3565/3750 [05:05<00:15, 11.66it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3566/3750 [05:05<00:15, 11.66it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3567/3750 [05:05<00:15, 11.66it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3568/3750 [05:05<00:15, 11.67it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3569/3750 [05:05<00:15, 11.67it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3570/3750 [05:05<00:15, 11.67it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|███████████████████▉ | 3571/3750 [05:05<00:15, 11.67it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3572/3750 [05:06<00:15, 11.67it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3573/3750 [05:06<00:15, 11.67it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3574/3750 [05:06<00:15, 11.68it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3575/3750 [05:06<00:14, 11.68it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3576/3750 [05:06<00:14, 11.68it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3577/3750 [05:06<00:14, 11.68it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3578/3750 [05:06<00:14, 11.68it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3579/3750 [05:06<00:14, 11.69it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3580/3750 [05:06<00:14, 11.69it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  95%|████████████████████ | 3581/3750 [05:06<00:14, 11.69it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3582/3750 [05:06<00:14, 11.69it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3583/3750 [05:06<00:14, 11.69it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3584/3750 [05:06<00:14, 11.70it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3585/3750 [05:06<00:14, 11.70it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3586/3750 [05:06<00:14, 11.70it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3587/3750 [05:06<00:13, 11.70it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3588/3750 [05:06<00:13, 11.70it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3589/3750 [05:06<00:13, 11.71it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3590/3750 [05:06<00:13, 11.71it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3591/3750 [05:06<00:13, 11.71it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3592/3750 [05:06<00:13, 11.71it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████ | 3593/3750 [05:06<00:13, 11.71it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3594/3750 [05:06<00:13, 11.72it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3595/3750 [05:06<00:13, 11.72it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3596/3750 [05:06<00:13, 11.72it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3597/3750 [05:06<00:13, 11.72it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3598/3750 [05:06<00:12, 11.72it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3599/3750 [05:06<00:12, 11.73it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3600/3750 [05:06<00:12, 11.73it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3601/3750 [05:06<00:12, 11.73it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3602/3750 [05:06<00:12, 11.73it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3603/3750 [05:07<00:12, 11.74it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3604/3750 [05:07<00:12, 11.74it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3605/3750 [05:07<00:12, 11.74it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3606/3750 [05:07<00:12, 11.74it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3607/3750 [05:07<00:12, 11.74it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3608/3750 [05:07<00:12, 11.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3609/3750 [05:07<00:12, 11.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3610/3750 [05:07<00:11, 11.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3611/3750 [05:07<00:11, 11.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3612/3750 [05:07<00:11, 11.75it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3613/3750 [05:07<00:11, 11.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3614/3750 [05:07<00:11, 11.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3615/3750 [05:07<00:11, 11.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▏| 3616/3750 [05:07<00:11, 11.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▎| 3617/3750 [05:07<00:11, 11.76it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  96%|████████████████████▎| 3618/3750 [05:07<00:11, 11.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|████████████████████▎| 3619/3750 [05:07<00:11, 11.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3620/3750 [05:07<00:11, 11.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3621/3750 [05:07<00:10, 11.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3622/3750 [05:07<00:10, 11.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3623/3750 [05:07<00:10, 11.77it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3624/3750 [05:07<00:10, 11.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3625/3750 [05:07<00:10, 11.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3626/3750 [05:07<00:10, 11.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3627/3750 [05:07<00:10, 11.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3628/3750 [05:07<00:10, 11.78it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3629/3750 [05:07<00:10, 11.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3630/3750 [05:07<00:10, 11.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3631/3750 [05:08<00:10, 11.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3632/3750 [05:08<00:10, 11.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3633/3750 [05:08<00:09, 11.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3634/3750 [05:08<00:09, 11.79it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3635/3750 [05:08<00:09, 11.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3636/3750 [05:08<00:09, 11.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3637/3750 [05:08<00:09, 11.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▎| 3638/3750 [05:08<00:09, 11.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3639/3750 [05:08<00:09, 11.80it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3640/3750 [05:08<00:09, 11.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3641/3750 [05:08<00:09, 11.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3642/3750 [05:08<00:09, 11.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3643/3750 [05:08<00:09, 11.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3644/3750 [05:08<00:08, 11.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3645/3750 [05:08<00:08, 11.81it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3646/3750 [05:08<00:08, 11.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3647/3750 [05:08<00:08, 11.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3648/3750 [05:08<00:08, 11.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3649/3750 [05:08<00:08, 11.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3650/3750 [05:08<00:08, 11.82it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3651/3750 [05:08<00:08, 11.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3652/3750 [05:08<00:08, 11.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3653/3750 [05:08<00:08, 11.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3654/3750 [05:08<00:08, 11.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3655/3750 [05:08<00:08, 11.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  97%|████████████████████▍| 3656/3750 [05:08<00:07, 11.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▍| 3657/3750 [05:09<00:07, 11.83it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▍| 3658/3750 [05:09<00:07, 11.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▍| 3659/3750 [05:09<00:07, 11.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▍| 3660/3750 [05:09<00:07, 11.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3661/3750 [05:09<00:07, 11.84it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3662/3750 [05:09<00:07, 11.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3663/3750 [05:09<00:07, 11.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3664/3750 [05:09<00:07, 11.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3665/3750 [05:09<00:07, 11.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3666/3750 [05:09<00:07, 11.85it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3667/3750 [05:09<00:07, 11.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3668/3750 [05:09<00:06, 11.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3669/3750 [05:09<00:06, 11.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3670/3750 [05:09<00:06, 11.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3671/3750 [05:09<00:06, 11.86it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3672/3750 [05:09<00:06, 11.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3673/3750 [05:09<00:06, 11.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3674/3750 [05:09<00:06, 11.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3675/3750 [05:09<00:06, 11.87it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3676/3750 [05:09<00:06, 11.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3677/3750 [05:09<00:06, 11.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3678/3750 [05:09<00:06, 11.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3679/3750 [05:09<00:05, 11.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3680/3750 [05:09<00:05, 11.88it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3681/3750 [05:09<00:05, 11.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3682/3750 [05:09<00:05, 11.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▌| 3683/3750 [05:09<00:05, 11.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3684/3750 [05:09<00:05, 11.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  98%|████████████████████▋| 3685/3750 [05:09<00:05, 11.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3686/3750 [05:09<00:05, 11.89it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3687/3750 [05:09<00:05, 11.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3688/3750 [05:09<00:05, 11.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3689/3750 [05:09<00:05, 11.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3690/3750 [05:09<00:05, 11.90it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3691/3750 [05:10<00:04, 11.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3692/3750 [05:10<00:04, 11.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  98%|████████████████████▋| 3693/3750 [05:10<00:04, 11.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3694/3750 [05:10<00:04, 11.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3695/3750 [05:10<00:04, 11.91it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3696/3750 [05:10<00:04, 11.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3697/3750 [05:10<00:04, 11.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3698/3750 [05:10<00:04, 11.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3699/3750 [05:10<00:04, 11.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3700/3750 [05:10<00:04, 11.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3701/3750 [05:10<00:04, 11.92it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3702/3750 [05:10<00:04, 11.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3703/3750 [05:10<00:03, 11.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3704/3750 [05:10<00:03, 11.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▋| 3705/3750 [05:10<00:03, 11.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3706/3750 [05:10<00:03, 11.93it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3707/3750 [05:10<00:03, 11.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3708/3750 [05:10<00:03, 11.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3709/3750 [05:10<00:03, 11.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3710/3750 [05:10<00:03, 11.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3711/3750 [05:10<00:03, 11.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3712/3750 [05:10<00:03, 11.94it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3713/3750 [05:10<00:03, 11.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3714/3750 [05:10<00:03, 11.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3715/3750 [05:10<00:02, 11.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3716/3750 [05:10<00:02, 11.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3717/3750 [05:10<00:02, 11.95it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3718/3750 [05:10<00:02, 11.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3719/3750 [05:11<00:02, 11.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3720/3750 [05:11<00:02, 11.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3721/3750 [05:11<00:02, 11.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3722/3750 [05:11<00:02, 11.96it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3723/3750 [05:11<00:02, 11.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3724/3750 [05:11<00:02, 11.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3725/3750 [05:11<00:02, 11.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3726/3750 [05:11<00:02, 11.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▊| 3727/3750 [05:11<00:01, 11.97it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▉| 3728/3750 [05:11<00:01, 11.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▉| 3729/3750 [05:11<00:01, 11.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▉| 3730/3750 [05:11<00:01, 11.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1:  99%|████████████████████▉| 3731/3750 [05:11<00:01, 11.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3732/3750 [05:11<00:01, 11.98it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3733/3750 [05:11<00:01, 11.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3734/3750 [05:11<00:01, 11.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3735/3750 [05:11<00:01, 11.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3736/3750 [05:11<00:01, 11.99it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3737/3750 [05:11<00:01, 12.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3738/3750 [05:11<00:01, 12.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3739/3750 [05:11<00:00, 12.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3740/3750 [05:11<00:00, 12.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3741/3750 [05:11<00:00, 12.00it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3742/3750 [05:11<00:00, 12.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3743/3750 [05:11<00:00, 12.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3744/3750 [05:11<00:00, 12.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3745/3750 [05:11<00:00, 12.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3746/3750 [05:11<00:00, 12.01it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3747/3750 [05:11<00:00, 12.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3748/3750 [05:11<00:00, 12.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|████████████████████▉| 3749/3750 [05:11<00:00, 12.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.637]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████| 3750/3750 [05:11<00:00, 12.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.543]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████| 3750/3750 [05:12<00:00, 12.02it/s, loss=0.561, v_num=0, acc=0.812, val_loss=0.543]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout the directory `lightning_logs`. For each run there is a new directory `version_xx` created. The rightmost argument in the progress bar, the `v_num` variable above shows the version of the current run. Each directory automatically contains a folder with checkpoints, logs and the hyperparameters for this run.\n",
    "\n",
    "As seen in the last notebook, you can have a look at the  logs of the runs in the TensorBoard  \n",
    "Use the command as in the previous notebook in your terminal \n",
    "```\n",
    "tensorboard --logdir lightning_logs\n",
    "```\n",
    "Make sure to use the above command as the same directory as `exercise_07`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, run the following cell to load the TensorBoard extension within the notebook. You may have to scroll to this block whenever you need to look at the TensorBoard interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Add images to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorboard logger is a submodule of the `LightningModule` and can be accessed via `self.logger`. We can  add images  to the logging module by calling \n",
    "```python\n",
    "self.logger.experiment.add_image('tag', image)\n",
    "```\n",
    "to add an image. \n",
    "\n",
    "\n",
    "We will log the first batch of validation images in a grid together with the predicted class labels and the ground truth labels. \n",
    "\n",
    "```python\n",
    "        if batch_idx == 0:\n",
    "            self.visualize_predictions(images, out.detach(), targets)\n",
    "```\n",
    "\n",
    "Let's have a look at the implementation of `visualize_predictions()` function in `exercise_code.lightning_models`.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "    def visualize_predictions(self, images, preds, targets):\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "        # determine size of the grid based on given batch size\n",
    "        num_rows = torch.tensor(len(images)).float().sqrt().floor()\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        for i in range(len(images)):\n",
    "            plt.subplot(num_rows ,len(images) // num_rows + 1, i+1)\n",
    "            plt.imshow(images[i].permute(1, 2, 0))\n",
    "            plt.title(class_names[torch.argmax(preds, axis=-1)[i]] + f'\\n[{class_names[targets[i]]}]')\n",
    "            plt.axis('off')\n",
    "\n",
    "        self.logger.experiment.add_figure('predictions', fig, global_step=self.global_step)\n",
    "```\n",
    "\n",
    "You can view the logged images in your `IMAGES` tab of TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now looked at how to train a model using PyTorch Lightning. PyTorch Lightning is very active in developement and the features set are continously expanded and updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Other Features of PyTorch Lightning\n",
    "\n",
    "\n",
    "### Checking  training timings\n",
    "\n",
    "The argument `profiler` of the `Trainer` class measures the time taken in different steps such as dataloading, forward and backward pass. You can select a variety of loggers [here](https://pytorch-lightning.readthedocs.io/en/stable/advanced/profiler.html).\n",
    "\n",
    "Run the cell below to see for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 407 K \n",
      "-------------------------------------\n",
      "407 K     Trainable params\n",
      "0         Non-trainable params\n",
      "407 K     Total params\n",
      "1.628     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|██████████████████████████████▊      | 3125/3750 [02:34<00:30, 20.19it/s, loss=0.529, v_num=1, acc=0.812]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                 | 0/625 [00:03<?, ?it/s]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3126/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3127/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3128/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▊      | 3129/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▉      | 3130/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████▉      | 3131/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3132/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3133/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3134/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3135/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3136/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3137/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3138/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3139/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3140/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████████████▉      | 3141/3750 [02:40<00:31, 19.53it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3142/3750 [02:40<00:31, 19.54it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3143/3750 [02:40<00:31, 19.54it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3144/3750 [02:40<00:31, 19.54it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3145/3750 [02:40<00:30, 19.54it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3146/3750 [02:40<00:30, 19.54it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3147/3750 [02:41<00:30, 19.54it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3148/3750 [02:41<00:30, 19.55it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3149/3750 [02:41<00:30, 19.55it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3150/3750 [02:41<00:30, 19.55it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3151/3750 [02:41<00:30, 19.55it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3152/3750 [02:41<00:30, 19.55it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3153/3750 [02:41<00:30, 19.55it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████      | 3154/3750 [02:41<00:30, 19.56it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3155/3750 [02:41<00:30, 19.56it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3156/3750 [02:41<00:30, 19.56it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3157/3750 [02:41<00:30, 19.56it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3158/3750 [02:41<00:30, 19.56it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3159/3750 [02:41<00:30, 19.56it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3160/3750 [02:41<00:30, 19.57it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3161/3750 [02:41<00:30, 19.57it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3162/3750 [02:41<00:30, 19.57it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3163/3750 [02:41<00:29, 19.57it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3164/3750 [02:41<00:29, 19.57it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3165/3750 [02:41<00:29, 19.57it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3166/3750 [02:41<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▏     | 3167/3750 [02:41<00:29, 19.57it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████████████▎     | 3168/3750 [02:41<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3169/3750 [02:41<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3170/3750 [02:41<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3171/3750 [02:41<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3172/3750 [02:41<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3173/3750 [02:42<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3174/3750 [02:42<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3175/3750 [02:42<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3176/3750 [02:42<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3177/3750 [02:42<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3178/3750 [02:42<00:29, 19.58it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▎     | 3179/3750 [02:42<00:29, 19.59it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3180/3750 [02:42<00:29, 19.59it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3181/3750 [02:42<00:29, 19.59it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3182/3750 [02:42<00:28, 19.59it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3183/3750 [02:42<00:28, 19.60it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3184/3750 [02:42<00:28, 19.59it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3185/3750 [02:42<00:28, 19.60it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3186/3750 [02:42<00:28, 19.60it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3187/3750 [02:42<00:28, 19.60it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3188/3750 [02:42<00:28, 19.61it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3189/3750 [02:42<00:28, 19.61it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|███████████████████████████████▍     | 3190/3750 [02:42<00:28, 19.61it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3191/3750 [02:42<00:28, 19.61it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▍     | 3192/3750 [02:42<00:28, 19.61it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3193/3750 [02:42<00:28, 19.62it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3194/3750 [02:42<00:28, 19.62it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3195/3750 [02:42<00:28, 19.62it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3196/3750 [02:42<00:28, 19.62it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3197/3750 [02:42<00:28, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3198/3750 [02:42<00:28, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3199/3750 [02:42<00:28, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3200/3750 [02:42<00:28, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3201/3750 [02:43<00:27, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3202/3750 [02:43<00:27, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3203/3750 [02:43<00:27, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3204/3750 [02:43<00:27, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▌     | 3205/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████████████▋     | 3206/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3207/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3208/3750 [02:43<00:27, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3209/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3210/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3211/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3212/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3213/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3214/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3215/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3216/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▋     | 3217/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3218/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3219/3750 [02:43<00:27, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3220/3750 [02:44<00:26, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3221/3750 [02:44<00:26, 19.63it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3222/3750 [02:44<00:26, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3223/3750 [02:44<00:26, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3224/3750 [02:44<00:26, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3225/3750 [02:44<00:26, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3226/3750 [02:44<00:26, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3227/3750 [02:44<00:26, 19.64it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3228/3750 [02:44<00:26, 19.65it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3229/3750 [02:44<00:26, 19.65it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▊     | 3230/3750 [02:44<00:26, 19.65it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3231/3750 [02:44<00:26, 19.65it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3232/3750 [02:44<00:26, 19.65it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3233/3750 [02:44<00:26, 19.65it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3234/3750 [02:44<00:26, 19.65it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3235/3750 [02:44<00:26, 19.66it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3236/3750 [02:44<00:26, 19.66it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3237/3750 [02:44<00:26, 19.66it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3238/3750 [02:44<00:26, 19.66it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3239/3750 [02:44<00:25, 19.66it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3240/3750 [02:44<00:25, 19.67it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3241/3750 [02:44<00:25, 19.67it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3242/3750 [02:44<00:25, 19.67it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████████████▉     | 3243/3750 [02:44<00:25, 19.67it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3244/3750 [02:44<00:25, 19.67it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3245/3750 [02:44<00:25, 19.68it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3246/3750 [02:44<00:25, 19.68it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3247/3750 [02:44<00:25, 19.68it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3248/3750 [02:45<00:25, 19.68it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3249/3750 [02:45<00:25, 19.68it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3250/3750 [02:45<00:25, 19.69it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3251/3750 [02:45<00:25, 19.69it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3252/3750 [02:45<00:25, 19.69it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3253/3750 [02:45<00:25, 19.69it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3254/3750 [02:45<00:25, 19.69it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████     | 3255/3750 [02:45<00:25, 19.70it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  87%|████████████████████████████████▏    | 3256/3750 [02:45<00:25, 19.70it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3257/3750 [02:45<00:25, 19.70it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3258/3750 [02:45<00:24, 19.70it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3259/3750 [02:45<00:24, 19.70it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3260/3750 [02:45<00:24, 19.70it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3261/3750 [02:45<00:24, 19.70it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3262/3750 [02:45<00:24, 19.71it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3263/3750 [02:45<00:24, 19.71it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3264/3750 [02:45<00:24, 19.71it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3265/3750 [02:45<00:24, 19.71it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3266/3750 [02:45<00:24, 19.71it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3267/3750 [02:45<00:24, 19.71it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▏    | 3268/3750 [02:45<00:24, 19.72it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3269/3750 [02:45<00:24, 19.72it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3270/3750 [02:45<00:24, 19.72it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3271/3750 [02:45<00:24, 19.72it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3272/3750 [02:45<00:24, 19.72it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3273/3750 [02:45<00:24, 19.72it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3274/3750 [02:46<00:24, 19.72it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3275/3750 [02:46<00:24, 19.73it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3276/3750 [02:46<00:24, 19.73it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3277/3750 [02:46<00:23, 19.73it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3278/3750 [02:46<00:23, 19.73it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3279/3750 [02:46<00:23, 19.73it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3280/3750 [02:46<00:23, 19.74it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████████████▎    | 3281/3750 [02:46<00:23, 19.74it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3282/3750 [02:46<00:23, 19.74it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3283/3750 [02:46<00:23, 19.74it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3284/3750 [02:46<00:23, 19.74it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3285/3750 [02:46<00:23, 19.74it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3286/3750 [02:46<00:23, 19.75it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3287/3750 [02:46<00:23, 19.75it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3288/3750 [02:46<00:23, 19.75it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3289/3750 [02:46<00:23, 19.75it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3290/3750 [02:46<00:23, 19.75it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3291/3750 [02:46<00:23, 19.75it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3292/3750 [02:46<00:23, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▍    | 3293/3750 [02:46<00:23, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3294/3750 [02:46<00:23, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3295/3750 [02:46<00:23, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3296/3750 [02:46<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3297/3750 [02:46<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3298/3750 [02:46<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3299/3750 [02:46<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3300/3750 [02:47<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3301/3750 [02:47<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3302/3750 [02:47<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3303/3750 [02:47<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3304/3750 [02:47<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3305/3750 [02:47<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▌    | 3306/3750 [02:47<00:22, 19.76it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3307/3750 [02:47<00:22, 19.77it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3308/3750 [02:47<00:22, 19.77it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3309/3750 [02:47<00:22, 19.77it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3310/3750 [02:47<00:22, 19.77it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3311/3750 [02:47<00:22, 19.77it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3312/3750 [02:47<00:22, 19.77it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3313/3750 [02:47<00:22, 19.78it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3314/3750 [02:47<00:22, 19.78it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3315/3750 [02:47<00:21, 19.78it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3316/3750 [02:47<00:21, 19.78it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3317/3750 [02:47<00:21, 19.78it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████████████▋    | 3318/3750 [02:47<00:21, 19.78it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▋    | 3319/3750 [02:47<00:21, 19.79it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3320/3750 [02:47<00:21, 19.79it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3321/3750 [02:47<00:21, 19.79it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  89%|████████████████████████████████▊    | 3322/3750 [02:47<00:21, 19.79it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3323/3750 [02:47<00:21, 19.79it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3324/3750 [02:47<00:21, 19.79it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3325/3750 [02:47<00:21, 19.79it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3326/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3327/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3328/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3329/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3330/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▊    | 3331/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3332/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3333/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3334/3750 [02:48<00:21, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3335/3750 [02:48<00:20, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3336/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3337/3750 [02:48<00:20, 19.80it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3338/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3339/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3340/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3341/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3342/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3343/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████▉    | 3344/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3345/3750 [02:48<00:20, 19.81it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3346/3750 [02:48<00:20, 19.82it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3347/3750 [02:48<00:20, 19.82it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3348/3750 [02:48<00:20, 19.82it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3349/3750 [02:48<00:20, 19.82it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3350/3750 [02:49<00:20, 19.82it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3351/3750 [02:49<00:20, 19.82it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3352/3750 [02:49<00:20, 19.83it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3353/3750 [02:49<00:20, 19.83it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3354/3750 [02:49<00:19, 19.83it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3355/3750 [02:49<00:19, 19.83it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████    | 3356/3750 [02:49<00:19, 19.83it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████    | 3357/3750 [02:49<00:19, 19.83it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3358/3750 [02:49<00:19, 19.84it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3359/3750 [02:49<00:19, 19.84it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3360/3750 [02:49<00:19, 19.84it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3361/3750 [02:49<00:19, 19.84it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3362/3750 [02:49<00:19, 19.84it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3363/3750 [02:49<00:19, 19.84it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3364/3750 [02:49<00:19, 19.84it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3365/3750 [02:49<00:19, 19.85it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3366/3750 [02:49<00:19, 19.85it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3367/3750 [02:49<00:19, 19.85it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3368/3750 [02:49<00:19, 19.85it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▏   | 3369/3750 [02:49<00:19, 19.86it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3370/3750 [02:49<00:19, 19.86it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3371/3750 [02:49<00:19, 19.86it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3372/3750 [02:49<00:19, 19.86it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3373/3750 [02:49<00:18, 19.86it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3374/3750 [02:49<00:18, 19.87it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3375/3750 [02:49<00:18, 19.87it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3376/3750 [02:49<00:18, 19.87it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3377/3750 [02:49<00:18, 19.87it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3378/3750 [02:49<00:18, 19.87it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3379/3750 [02:50<00:18, 19.88it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3380/3750 [02:50<00:18, 19.88it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3381/3750 [02:50<00:18, 19.88it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▎   | 3382/3750 [02:50<00:18, 19.88it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3383/3750 [02:50<00:18, 19.88it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3384/3750 [02:50<00:18, 19.88it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3385/3750 [02:50<00:18, 19.88it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3386/3750 [02:50<00:18, 19.89it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3387/3750 [02:50<00:18, 19.89it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|█████████████████████████████████▍   | 3388/3750 [02:50<00:18, 19.89it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3389/3750 [02:50<00:18, 19.89it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3390/3750 [02:50<00:18, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3391/3750 [02:50<00:18, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3392/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████████████▍   | 3393/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▍   | 3394/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▍   | 3395/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3396/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3397/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3398/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3399/3750 [02:50<00:17, 19.90it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3400/3750 [02:50<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3401/3750 [02:50<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3402/3750 [02:50<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3403/3750 [02:50<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3404/3750 [02:50<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3405/3750 [02:51<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3406/3750 [02:51<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▌   | 3407/3750 [02:51<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3408/3750 [02:51<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3409/3750 [02:51<00:17, 19.91it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3410/3750 [02:51<00:17, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3411/3750 [02:51<00:17, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3412/3750 [02:51<00:16, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3413/3750 [02:51<00:16, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3414/3750 [02:51<00:16, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3415/3750 [02:51<00:16, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3416/3750 [02:51<00:16, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3417/3750 [02:51<00:16, 19.92it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3418/3750 [02:51<00:16, 19.93it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3419/3750 [02:51<00:16, 19.93it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▋   | 3420/3750 [02:51<00:16, 19.93it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3421/3750 [02:51<00:16, 19.93it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3422/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3423/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3424/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3425/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3426/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3427/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3428/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3429/3750 [02:51<00:16, 19.94it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3430/3750 [02:51<00:16, 19.95it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████████████▊   | 3431/3750 [02:51<00:15, 19.95it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▊   | 3432/3750 [02:52<00:15, 19.95it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▊   | 3433/3750 [02:52<00:15, 19.95it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3434/3750 [02:52<00:15, 19.95it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3435/3750 [02:52<00:15, 19.95it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3436/3750 [02:52<00:15, 19.95it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3437/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3438/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3439/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3440/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3441/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3442/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3443/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3444/3750 [02:52<00:15, 19.96it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████████████▉   | 3445/3750 [02:52<00:15, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3446/3750 [02:52<00:15, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3447/3750 [02:52<00:15, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3448/3750 [02:52<00:15, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3449/3750 [02:52<00:15, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3450/3750 [02:52<00:15, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3451/3750 [02:52<00:14, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3452/3750 [02:52<00:14, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3453/3750 [02:52<00:14, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|██████████████████████████████████   | 3454/3750 [02:52<00:14, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3455/3750 [02:52<00:14, 19.97it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3456/3750 [02:53<00:14, 19.98it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3457/3750 [02:53<00:14, 19.98it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████   | 3458/3750 [02:53<00:14, 19.98it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3459/3750 [02:53<00:14, 19.98it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3460/3750 [02:53<00:14, 19.98it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3461/3750 [02:53<00:14, 19.98it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3462/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3463/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3464/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3465/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3466/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3467/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████████████████▏  | 3468/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▏  | 3469/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▏  | 3470/3750 [02:53<00:14, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▏  | 3471/3750 [02:53<00:13, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3472/3750 [02:53<00:13, 19.99it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3473/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3474/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3475/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3476/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3477/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3478/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3479/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3480/3750 [02:53<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3481/3750 [02:54<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3482/3750 [02:54<00:13, 20.00it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▎  | 3483/3750 [02:54<00:13, 20.01it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3484/3750 [02:54<00:13, 20.01it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3485/3750 [02:54<00:13, 20.01it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3486/3750 [02:54<00:13, 20.01it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3487/3750 [02:54<00:13, 20.01it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3488/3750 [02:54<00:13, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3489/3750 [02:54<00:13, 20.01it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3490/3750 [02:54<00:12, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3491/3750 [02:54<00:12, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3492/3750 [02:54<00:12, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3493/3750 [02:54<00:12, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3494/3750 [02:54<00:12, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3495/3750 [02:54<00:12, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▍  | 3496/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3497/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3498/3750 [02:54<00:12, 20.02it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3499/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3500/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3501/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3502/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3503/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3504/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3505/3750 [02:54<00:12, 20.03it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████▌  | 3506/3750 [02:54<00:12, 20.04it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▌  | 3507/3750 [02:55<00:12, 20.04it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▌  | 3508/3750 [02:55<00:12, 20.04it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▌  | 3509/3750 [02:55<00:12, 20.04it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3510/3750 [02:55<00:11, 20.04it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3511/3750 [02:55<00:11, 20.05it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3512/3750 [02:55<00:11, 20.05it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3513/3750 [02:55<00:11, 20.05it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3514/3750 [02:55<00:11, 20.05it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3515/3750 [02:55<00:11, 20.05it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3516/3750 [02:55<00:11, 20.06it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3517/3750 [02:55<00:11, 20.06it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3518/3750 [02:55<00:11, 20.06it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3519/3750 [02:55<00:11, 20.06it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94%|██████████████████████████████████▋  | 3520/3750 [02:55<00:11, 20.06it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▋  | 3521/3750 [02:55<00:11, 20.06it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3522/3750 [02:55<00:11, 20.06it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3523/3750 [02:55<00:11, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3524/3750 [02:55<00:11, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3525/3750 [02:55<00:11, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3526/3750 [02:55<00:11, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3527/3750 [02:55<00:11, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3528/3750 [02:55<00:11, 20.08it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3529/3750 [02:55<00:11, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3530/3750 [02:55<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3531/3750 [02:55<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3532/3750 [02:55<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3533/3750 [02:56<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▊  | 3534/3750 [02:56<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3535/3750 [02:56<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3536/3750 [02:56<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3537/3750 [02:56<00:10, 20.07it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3538/3750 [02:56<00:10, 20.08it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3539/3750 [02:56<00:10, 20.08it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3540/3750 [02:56<00:10, 20.08it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3541/3750 [02:56<00:10, 20.08it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3542/3750 [02:56<00:10, 20.08it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████████████▉  | 3543/3750 [02:56<00:10, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3544/3750 [02:56<00:10, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3545/3750 [02:56<00:10, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3546/3750 [02:56<00:10, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████▉  | 3547/3750 [02:56<00:10, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3548/3750 [02:56<00:10, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3549/3750 [02:56<00:10, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3550/3750 [02:56<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3551/3750 [02:56<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3552/3750 [02:56<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3553/3750 [02:56<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3554/3750 [02:56<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3555/3750 [02:56<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3556/3750 [02:56<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3557/3750 [02:57<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3558/3750 [02:57<00:09, 20.09it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████  | 3559/3750 [02:57<00:09, 20.10it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3560/3750 [02:57<00:09, 20.10it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3561/3750 [02:57<00:09, 20.10it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3562/3750 [02:57<00:09, 20.10it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3563/3750 [02:57<00:09, 20.10it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3564/3750 [02:57<00:09, 20.10it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3565/3750 [02:57<00:09, 20.10it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3566/3750 [02:57<00:09, 20.11it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3567/3750 [02:57<00:09, 20.11it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3568/3750 [02:57<00:09, 20.11it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3569/3750 [02:57<00:09, 20.11it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3570/3750 [02:57<00:08, 20.11it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3571/3750 [02:57<00:08, 20.11it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▏ | 3572/3750 [02:57<00:08, 20.12it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3573/3750 [02:57<00:08, 20.12it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3574/3750 [02:57<00:08, 20.12it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3575/3750 [02:57<00:08, 20.12it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3576/3750 [02:57<00:08, 20.12it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3577/3750 [02:57<00:08, 20.12it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3578/3750 [02:57<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3579/3750 [02:57<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3580/3750 [02:57<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████████████████▎ | 3581/3750 [02:57<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3582/3750 [02:57<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3583/3750 [02:57<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3584/3750 [02:58<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▎ | 3585/3750 [02:58<00:08, 20.13it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  96%|███████████████████████████████████▍ | 3586/3750 [02:58<00:08, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3587/3750 [02:58<00:08, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3588/3750 [02:58<00:08, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3589/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3590/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3591/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3592/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3593/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3594/3750 [02:58<00:07, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3595/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3596/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▍ | 3597/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3598/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3599/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3600/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3601/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3602/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3603/3750 [02:58<00:07, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3604/3750 [02:58<00:07, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3605/3750 [02:58<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3606/3750 [02:59<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3607/3750 [02:59<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3608/3750 [02:59<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3609/3750 [02:59<00:07, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▌ | 3610/3750 [02:59<00:06, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3611/3750 [02:59<00:06, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3612/3750 [02:59<00:06, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3613/3750 [02:59<00:06, 20.14it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3614/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3615/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3616/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3617/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████████████▋ | 3618/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3619/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3620/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3621/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3622/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▋ | 3623/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3624/3750 [02:59<00:06, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3625/3750 [02:59<00:06, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3626/3750 [02:59<00:06, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3627/3750 [02:59<00:06, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3628/3750 [02:59<00:06, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3629/3750 [03:00<00:06, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3630/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3631/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3632/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3633/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3634/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▊ | 3635/3750 [03:00<00:05, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3636/3750 [03:00<00:05, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3637/3750 [03:00<00:05, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3638/3750 [03:00<00:05, 20.15it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3639/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3640/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3641/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3642/3750 [03:00<00:05, 20.16it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3643/3750 [03:00<00:05, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3644/3750 [03:00<00:05, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3645/3750 [03:00<00:05, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3646/3750 [03:00<00:05, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3647/3750 [03:00<00:05, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████████████▉ | 3648/3750 [03:00<00:05, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3649/3750 [03:00<00:05, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3650/3750 [03:00<00:04, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3651/3750 [03:00<00:04, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|████████████████████████████████████ | 3652/3750 [03:01<00:04, 20.18it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3653/3750 [03:01<00:04, 20.17it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3654/3750 [03:01<00:04, 20.18it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3655/3750 [03:01<00:04, 20.18it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████████████████ | 3656/3750 [03:01<00:04, 20.18it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3657/3750 [03:01<00:04, 20.18it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3658/3750 [03:01<00:04, 20.18it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3659/3750 [03:01<00:04, 20.19it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3660/3750 [03:01<00:04, 20.19it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████ | 3661/3750 [03:01<00:04, 20.19it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3662/3750 [03:01<00:04, 20.19it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3663/3750 [03:01<00:04, 20.19it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3664/3750 [03:01<00:04, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3665/3750 [03:01<00:04, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3666/3750 [03:01<00:04, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3667/3750 [03:01<00:04, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3668/3750 [03:01<00:04, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3669/3750 [03:01<00:04, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3670/3750 [03:01<00:03, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3671/3750 [03:01<00:03, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3672/3750 [03:01<00:03, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▏| 3673/3750 [03:01<00:03, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3674/3750 [03:01<00:03, 20.20it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3675/3750 [03:01<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3676/3750 [03:01<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3677/3750 [03:01<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3678/3750 [03:02<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3679/3750 [03:02<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3680/3750 [03:02<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3681/3750 [03:02<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3682/3750 [03:02<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3683/3750 [03:02<00:03, 20.22it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3684/3750 [03:02<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3685/3750 [03:02<00:03, 20.21it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▎| 3686/3750 [03:02<00:03, 20.22it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3687/3750 [03:02<00:03, 20.22it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3688/3750 [03:02<00:03, 20.22it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3689/3750 [03:02<00:03, 20.22it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3690/3750 [03:02<00:02, 20.22it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3691/3750 [03:02<00:02, 20.23it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3692/3750 [03:02<00:02, 20.23it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████▍| 3693/3750 [03:02<00:02, 20.23it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3694/3750 [03:02<00:02, 20.23it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3695/3750 [03:02<00:02, 20.23it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3696/3750 [03:02<00:02, 20.23it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3697/3750 [03:02<00:02, 20.24it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3698/3750 [03:02<00:02, 20.24it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▍| 3699/3750 [03:02<00:02, 20.24it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3700/3750 [03:02<00:02, 20.24it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3701/3750 [03:02<00:02, 20.24it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3702/3750 [03:02<00:02, 20.24it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3703/3750 [03:02<00:02, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3704/3750 [03:02<00:02, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3705/3750 [03:02<00:02, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3706/3750 [03:03<00:02, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3707/3750 [03:03<00:02, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3708/3750 [03:03<00:02, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3709/3750 [03:03<00:02, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3710/3750 [03:03<00:01, 20.25it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▌| 3711/3750 [03:03<00:01, 20.26it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3712/3750 [03:03<00:01, 20.26it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3713/3750 [03:03<00:01, 20.26it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3714/3750 [03:03<00:01, 20.26it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3715/3750 [03:03<00:01, 20.26it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3716/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3717/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|████████████████████████████████████▋| 3718/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3719/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3720/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3721/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3722/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3723/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▋| 3724/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3725/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3726/3750 [03:03<00:01, 20.27it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3727/3750 [03:03<00:01, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3728/3750 [03:03<00:01, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3729/3750 [03:03<00:01, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3730/3750 [03:03<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 3731/3750 [03:03<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3732/3750 [03:04<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3733/3750 [03:04<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3734/3750 [03:04<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3735/3750 [03:04<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3736/3750 [03:04<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 3737/3750 [03:04<00:00, 20.28it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3738/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3739/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3740/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3741/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3742/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3743/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3744/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3745/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3746/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3747/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3748/3750 [03:04<00:00, 20.30it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 3749/3750 [03:04<00:00, 20.30it/s, loss=0.529, v_num=1, acc=0.812]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████| 3750/3750 [03:04<00:00, 20.30it/s, loss=0.529, v_num=1, acc=0.812, val_loss=0.503]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████| 3750/3750 [03:04<00:00, 20.29it/s, loss=0.529, v_num=1, acc=0.812, val_loss=0.503]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\r\n",
      "\r\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "|  Action                                                                                                                                                                                                    \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\r\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "|  Total                                                                                                                                                                                                     \t|  -              \t|  137063         \t|  190.59         \t|  100 %          \t|\r\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "|  run_training_epoch                                                                                                                                                                                        \t|  184.78         \t|  1              \t|  184.78         \t|  96.95          \t|\r\n",
      "|  run_training_batch                                                                                                                                                                                        \t|  0.029755       \t|  3125           \t|  92.984         \t|  48.786         \t|\r\n",
      "|  [LightningModule]TwoLayerNet.optimizer_step                                                                                                                                                               \t|  0.028511       \t|  3125           \t|  89.097         \t|  46.747         \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                                                              \t|  0.011762       \t|  3125           \t|  36.757         \t|  19.285         \t|\r\n",
      "|  on_train_batch_end                                                                                                                                                                                        \t|  0.010486       \t|  3125           \t|  32.77          \t|  17.194         \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                                                                   \t|  0.007528       \t|  3125           \t|  23.525         \t|  12.343         \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                                                         \t|  0.021848       \t|  627            \t|  13.699         \t|  7.1875         \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                                                            \t|  0.014702       \t|  627            \t|  9.218          \t|  4.8365         \t|\r\n",
      "|  [LightningModule]TwoLayerNet.optimizer_zero_grad                                                                                                                                                          \t|  0.0020819      \t|  3125           \t|  6.506          \t|  3.4135         \t|\r\n",
      "|  on_train_batch_start                                                                                                                                                                                      \t|  0.0009408      \t|  3125           \t|  2.94           \t|  1.5425         \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                                                            \t|  0.00027399     \t|  3752           \t|  1.028          \t|  0.53937        \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_batch_start                                                                                                                                                                  \t|  5.024e-05      \t|  3125           \t|  0.157          \t|  0.082374       \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_batch_start                     \t|  4.544e-05      \t|  3125           \t|  0.142          \t|  0.074504       \t|\r\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                                                                  \t|  4.544e-05      \t|  3125           \t|  0.142          \t|  0.074504       \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                                                             \t|  4.448e-05      \t|  3125           \t|  0.139          \t|  0.07293        \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                                                              \t|  4.064e-05      \t|  3125           \t|  0.127          \t|  0.066634       \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_optimizer_step                                                                                                                                          \t|  4.032e-05      \t|  3125           \t|  0.126          \t|  0.066109       \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                                                               \t|  3.552e-05      \t|  3125           \t|  0.111          \t|  0.058239       \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_after_backward                  \t|  3.52e-05       \t|  3125           \t|  0.11           \t|  0.057714       \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_batch_start                                                                                                                                                    \t|  3.04e-05       \t|  3125           \t|  0.095          \t|  0.049844       \t|\r\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                                                                \t|  3.008e-05      \t|  3125           \t|  0.094          \t|  0.049319       \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_backward                                                                                                                                                \t|  2.944e-05      \t|  3125           \t|  0.092          \t|  0.04827        \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_backward                 \t|  2.528e-05      \t|  3125           \t|  0.079          \t|  0.041449       \t|\r\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                                                                 \t|  2.496e-05      \t|  3125           \t|  0.078          \t|  0.040925       \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_optimizer_step           \t|  2.464e-05      \t|  3125           \t|  0.077          \t|  0.0404         \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_after_backward                                                                                                                                                 \t|  2.016e-05      \t|  3125           \t|  0.063          \t|  0.033055       \t|\r\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                                                           \t|  2.016e-05      \t|  3125           \t|  0.063          \t|  0.033055       \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_batch_end                       \t|  2.016e-05      \t|  3125           \t|  0.063          \t|  0.033055       \t|\r\n",
      "|  [Callback]ModelSummary.on_batch_start                                                                                                                                                                     \t|  1.984e-05      \t|  3125           \t|  0.062          \t|  0.03253        \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_after_backward                                                                                                                                                            \t|  1.984e-05      \t|  3125           \t|  0.062          \t|  0.03253        \t|\r\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                                                            \t|  9.7289e-05     \t|  627            \t|  0.061          \t|  0.032005       \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_zero_grad                                                                                                                                               \t|  1.536e-05      \t|  3125           \t|  0.048          \t|  0.025184       \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_end                 \t|  0.047          \t|  1              \t|  0.047          \t|  0.02466        \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_zero_grad                \t|  1.472e-05      \t|  3125           \t|  0.046          \t|  0.024135       \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_batch_end                                                                                                                                                                    \t|  1.472e-05      \t|  3125           \t|  0.046          \t|  0.024135       \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_train_batch_end                                                                                                                                                           \t|  1.024e-05      \t|  3125           \t|  0.032          \t|  0.01679        \t|\r\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                                                          \t|  5.1037e-05     \t|  627            \t|  0.032          \t|  0.01679        \t|\r\n",
      "|  [LightningModule]TwoLayerNet.validation_epoch_end                                                                                                                                                         \t|  0.016          \t|  2              \t|  0.032          \t|  0.01679        \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_before_zero_grad                                                                                                                                                          \t|  1.024e-05      \t|  3125           \t|  0.032          \t|  0.01679        \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_train_batch_start                                                                                                                                                         \t|  9.92e-06       \t|  3125           \t|  0.031          \t|  0.016265       \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                                                       \t|  9.92e-06       \t|  3125           \t|  0.031          \t|  0.016265       \t|\r\n",
      "|  [LightningModule]TwoLayerNet.training_step_end                                                                                                                                                            \t|  9.92e-06       \t|  3125           \t|  0.031          \t|  0.016265       \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                                                        \t|  9.92e-06       \t|  3125           \t|  0.031          \t|  0.016265       \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.training_step_end                                                                                                                                                          \t|  9.6e-06        \t|  3125           \t|  0.03           \t|  0.01574        \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                                                       \t|  2.5518e-05     \t|  627            \t|  0.016          \t|  0.0083948      \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_batch_end            \t|  2.5518e-05     \t|  627            \t|  0.016          \t|  0.0083948      \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_before_backward                                                                                                                                                           \t|  5.12e-06       \t|  3125           \t|  0.016          \t|  0.0083948      \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_before_optimizer_step                                                                                                                                                     \t|  5.12e-06       \t|  3125           \t|  0.016          \t|  0.0083948      \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_batch_start          \t|  2.3923e-05     \t|  627            \t|  0.015          \t|  0.0078701      \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_batch_start                                                                                                                                                    \t|  2.3923e-05     \t|  627            \t|  0.015          \t|  0.0078701      \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_batch_end                                                                                                                                           \t|  2.3923e-05     \t|  627            \t|  0.015          \t|  0.0078701      \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                                                               \t|  0.0075         \t|  2              \t|  0.015          \t|  0.0078701      \t|\r\n",
      "|  [LightningModule]TwoLayerNet.configure_callbacks                                                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.prepare_data                                                                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_before_accelerator_backend_setup                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_before_accelerator_backend_setup                                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_accelerator_backend_setup                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': None}.on_before_accelerator_backend_setup\t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.setup                                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': None}.setup                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.setup                                                                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.configure_sharded_model                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_configure_sharded_model                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_configure_sharded_model                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_configure_sharded_model                                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_configure_sharded_model         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.configure_optimizers                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_fit_start                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_start                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_fit_start                                                                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_pretrain_routine_start                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_pretrain_routine_start                                                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_pretrain_routine_start                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_pretrain_routine_start          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_pretrain_routine_start                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_pretrain_routine_end                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_pretrain_routine_end                                                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_pretrain_routine_end                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_pretrain_routine_end            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_pretrain_routine_end                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_sanity_check_start                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_sanity_check_start              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_val_dataloader                                                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_model_eval                                                                                                                                                     \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                                                             \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                                                                \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_start                                                                                                                                               \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_start                \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_start                                                                                                                                                          \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                                                        \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_epoch_start                                                                                                                                                                  \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_epoch_start                                                                                                                                                                     \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_epoch_start                                                                                                                                                    \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_epoch_start                     \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_epoch_start                                                                                                                                                               \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                                                       \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                                                          \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_epoch_start                                                                                                                                         \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_epoch_start          \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_epoch_start                                                                                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_batch_start                                                                                                                                         \t|  0.0            \t|  627            \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.validation_step_end                                                                                                                                                          \t|  0.0            \t|  627            \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step_end                                                                                                                                                        \t|  0.0            \t|  627            \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_batch_end                                                                                                                                                      \t|  0.0            \t|  627            \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                                                         \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                                                            \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_epoch_end                                                                                                                                           \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_epoch_end            \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_epoch_end                                                                                                                                                      \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_epoch_end                                                                                                                                                                    \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_epoch_end                                                                                                                                                                       \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_epoch_end                                                                                                                                                      \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_epoch_end                       \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_epoch_end                                                                                                                                                                 \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_end                                                                                                                                                 \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_end                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_end                                                                                                                                                            \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                                                          \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_validation_model_train                                                                                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_sanity_check_end                                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_sanity_check_end                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_train_dataloader                                                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_start                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_start                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_train_start                                                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_epoch_start                                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_start               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_train_epoch_start                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_batch_end                                                                                                                                                                       \t|  0.0            \t|  3125           \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_batch_end                                                                                                                                                      \t|  0.0            \t|  3125           \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_epoch_end                                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_save_checkpoint                                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_save_checkpoint                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_save_checkpoint                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_train_epoch_end                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_end                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_end                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_train_end                                                                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.on_fit_end                                                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_end                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.on_fit_end                                                                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]GradientAccumulationScheduler.teardown                                                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.teardown                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "|  [LightningModule]TwoLayerNet.teardown                                                                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\r\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    profiler='simple',\n",
    "    max_epochs=1,\n",
    "    # gpus=1 # Use GPU if available\n",
    "   \n",
    ")\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an overview of the time taken for different steps.\n",
    "This  enables us to detect bottlenecks in the model more easily. A bottleneck can be, for example, long times in dataloading. It becomes very important later, especially, when you start to implement custom layers or loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more debugging Options\n",
    "\n",
    "* [`fast_dev_run`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#fast-dev-run): Runs of batch of each train, validation and test pass (if validation and test datalaoders are passed as arguments).This is a fast way to check if everything works (dataloading, validation metric, model saving/ loading) without having to wait for a full epoch.\n",
    "\n",
    "* [`track_grad_norm`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#track-grad-norm): Logs the  norm of the gradients (set to `1` for the $L1$ norm or `2` for the $L2$ norm) for each layer. You can check whether the network is actually doing something. If the gradients are too small or too high, you won't have a good training (due to vanishing/ exploding gradients).\n",
    "\n",
    "\n",
    "### Other Features\n",
    "\n",
    "Finally, we want to mention some other useful options in the Trainer class:\n",
    "\n",
    "* [`resume_from_checkpoint`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#resume-from-checkpoint): Start the training from a checkpoint saved earlier. Argument is the path to the saved model file.\n",
    "* [`Callbacks`](https://pytorch-lightning.readthedocs.io/en/latest/callbacks.html#callback): Callbacks are extremely useful system during training that automate non essential code such as  storing model checkpoints , saving weights values among others.\n",
    "\n",
    "Let's have the look at the [`EarlyStopping`](https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html#early-stopping-based-on-metric-using-the-earlystopping-callback)  callback.\n",
    "\n",
    "It interrupts the training if the `monitor` metric variable does not  improve for `patience` number of epochs.\n",
    "\n",
    "Below is a code example on how to apply it!\n",
    "\n",
    "```python\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   patience=3,\n",
    "   verbose=False,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=10,callbacks=[early_stop_callback])\n",
    "```\n",
    "\n",
    "Your journey with pytorch lightning will force you to check out a bunch of callbacks to return the desired functions without having to write the respective code yourself. Or you hack it in, do as you wish :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. PyTorch Lightining [`Source Code`](https://github.com/PyTorchLightning/pytorch-lightning) with a nice introduction \n",
    "2. PyTorch Lightining [`Documentation`](https://pytorch-lightning.readthedocs.io/en/latest/#)  Explore it! The features are very well explained. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbf148f741bdcfda68412a690aa89cb477d7b565ce205d715d0eac6f68c7216c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
